<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 8.0.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous" defer></script><script class="next-config" data-name="main" type="application/json">{"hostname":"mjy.js.org","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.25.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":"ture","style":"default"},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script><meta name="description" content="T²EA：Target-Aware Taylor Expansion Approximation Network for Infrared &amp; Visible Fusion"><meta property="og:type" content="article"><meta property="og:title" content="【论文阅读 | TCSVT 2025 | T²EA：目标感知泰勒展开近似网络】"><meta property="og:url" content="https://mjy.js.org/2025/12/18/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20%20TCSVT%202025%20%20T%C2%B2EA%EF%BC%9A%E7%9B%AE%E6%A0%87%E6%84%9F%E7%9F%A5%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80%E8%BF%91%E4%BC%BC%E7%BD%91%E7%BB%9C%E3%80%91/index.html"><meta property="og:site_name" content="TranquilYu&#39;s Blog"><meta property="og:description" content="T²EA：Target-Aware Taylor Expansion Approximation Network for Infrared &amp; Visible Fusion"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://mjy.js.org/images/image-20251221071909426.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251221072301509.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251221081723587.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251221081738903.png"><meta property="article:published_time" content="2025-12-18T00:00:00.000Z"><meta property="article:modified_time" content="2025-12-21T01:12:45.556Z"><meta property="article:author" content="MaJianyu"><meta property="article:tag" content="Taylor展开"><meta property="article:tag" content="分割联合优化"><meta property="article:tag" content="双分支融合"><meta property="article:tag" content="目标感知"><meta property="article:tag" content="红外可见光融合"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://mjy.js.org/images/image-20251221071909426.png"><link rel="canonical" href="https://mjy.js.org/2025/12/18/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20%20TCSVT%202025%20%20T%C2%B2EA%EF%BC%9A%E7%9B%AE%E6%A0%87%E6%84%9F%E7%9F%A5%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80%E8%BF%91%E4%BC%BC%E7%BD%91%E7%BB%9C%E3%80%91/"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://mjy.js.org/2025/12/18/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20%20TCSVT%202025%20%20T%C2%B2EA%EF%BC%9A%E7%9B%AE%E6%A0%87%E6%84%9F%E7%9F%A5%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80%E8%BF%91%E4%BC%BC%E7%BD%91%E7%BB%9C%E3%80%91/","path":"2025/12/18/【论文阅读  TCSVT 2025  T²EA：目标感知泰勒展开近似网络】/","title":"【论文阅读 | TCSVT 2025 | T²EA：目标感知泰勒展开近似网络】"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>【论文阅读 | TCSVT 2025 | T²EA：目标感知泰勒展开近似网络】 | TranquilYu's Blog</title><script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous" defer></script><script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script><script src="/js/pjax.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.5.0/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script><script src="/js/third-party/search/local-search.js" defer></script><script src="/js/third-party/fancybox.js" defer></script><script src="/js/third-party/pace.js" defer></script><script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":"flase","tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src="/js/third-party/math/mathjax.js" defer></script><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" integrity="sha512-fHwaWebuwA7NSF5Qg/af4UeDx9XqUpYpOGgubo3yWu+b2IQR4UeQwbb42Ti7gVAjNtVoI/I9TEoYeu9omwcC6g==" crossorigin="anonymous" referrerpolicy="no-referrer"><link rel="alternate" href="/atom.xml" title="TranquilYu's Blog" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">TranquilYu's Blog</p><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-%E7%A0%94%E7%A9%B6%E8%83%8C%E6%99%AF%E4%B8%8E%E5%8A%A8%E6%9C%BA"><span class="nav-number">1.</span> <span class="nav-text">1. 研究背景与动机</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-%E7%BA%A2%E5%A4%96-%E5%8F%AF%E8%A7%81%E5%85%89%E8%9E%8D%E5%90%88%E7%9A%84%E9%9C%80%E6%B1%82"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 红外-可见光融合的需求</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-%E7%8E%B0%E6%9C%89%E6%96%B9%E6%B3%95%E5%B1%80%E9%99%90"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 现有方法局限</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-%E6%9C%AC%E6%96%87%E8%B4%A1%E7%8C%AE"><span class="nav-number">1.3.</span> <span class="nav-text">1.3 本文贡献</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-%E6%95%B4%E4%BD%93%E6%A1%86%E6%9E%B6"><span class="nav-number">2.</span> <span class="nav-text">2. 整体框架</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80%E8%BF%91%E4%BC%BC%EF%BC%88TEA%EF%BC%89%E7%BD%91%E7%BB%9C"><span class="nav-number">3.</span> <span class="nav-text">3. 泰勒展开近似（TEA）网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80%E7%90%86%E8%AE%BA"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 泰勒展开理论</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AE%9E%E7%8E%B0"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 网络架构与实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-1-%E6%98%A0%E5%B0%84%E7%BD%91%E7%BB%9C"><span class="nav-number">3.2.1.</span> <span class="nav-text">3.2.1 映射网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-2-%E5%AF%BC%E6%95%B0%E7%BD%91%E7%BB%9C"><span class="nav-number">3.2.2.</span> <span class="nav-text">3.2.2 导数网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-3-%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84"><span class="nav-number">3.2.3.</span> <span class="nav-text">3.2.3 网络架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-4-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.4.</span> <span class="nav-text">3.2.4 损失函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 网络优化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-%E5%8F%8C%E5%88%86%E6%94%AF%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%EF%BC%88DBFF%EF%BC%89%E7%BD%91%E7%BB%9C"><span class="nav-number">4.</span> <span class="nav-text">4. 双分支特征融合（DBFF）网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="nav-number">4.1.</span> <span class="nav-text">4.1 网络架构概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-1-%E5%8F%8C%E5%88%86%E6%94%AF%E7%BB%93%E6%9E%84"><span class="nav-number">4.1.1.</span> <span class="nav-text">4.1.1 双分支结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-2-%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88"><span class="nav-number">4.1.2.</span> <span class="nav-text">4.1.2 特征融合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-3-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="nav-number">4.1.3.</span> <span class="nav-text">4.1.3 注意力机制</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">4.2.</span> <span class="nav-text">4.2 损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-1-%E5%BC%BA%E5%BA%A6%E6%8D%9F%E5%A4%B1%EF%BC%88Intensity-Loss%EF%BC%89"><span class="nav-number">4.2.1.</span> <span class="nav-text">4.2.1 强度损失（Intensity Loss）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-2-%E7%BA%B9%E7%90%86%E7%BB%86%E8%8A%82%E6%8D%9F%E5%A4%B1%EF%BC%88Texture-Loss%EF%BC%89"><span class="nav-number">4.2.2.</span> <span class="nav-text">4.2.2 纹理细节损失（Texture Loss）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-3-%E6%80%BB%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">4.2.3.</span> <span class="nav-text">4.2.3 总损失函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96"><span class="nav-number">4.3.</span> <span class="nav-text">4.3 网络优化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-4-%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93"><span class="nav-number">4.4.</span> <span class="nav-text">4.4 网络总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%B8%8E%E7%9B%AE%E6%A0%87%E4%BC%98%E5%8C%96"><span class="nav-number">5.</span> <span class="nav-text">5. 语义分割与目标优化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C"><span class="nav-number">5.1.</span> <span class="nav-text">5.1 语义分割网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">5.2.</span> <span class="nav-text">5.2 损失函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-%E4%BB%BB%E5%8A%A1%E8%81%94%E5%90%88%E4%BC%98%E5%8C%96%EF%BC%88%E7%9B%AE%E6%A0%87%E6%84%9F%E7%9F%A5%EF%BC%89"><span class="nav-number">6.</span> <span class="nav-text">6. 任务联合优化（目标感知）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#6-1-%E6%80%9D%E8%B7%AF"><span class="nav-number">6.1.</span> <span class="nav-text">6.1 思路</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-2-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">6.2.</span> <span class="nav-text">6.2 损失函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-3-%E6%80%BB%E6%8D%9F%E5%A4%B1%E4%B8%8E%E8%B0%83%E5%BA%A6"><span class="nav-number">6.3.</span> <span class="nav-text">6.3 总损失与调度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-4-%E8%AE%AD%E7%BB%83%E8%AE%BE%E7%BD%AE"><span class="nav-number">6.4.</span> <span class="nav-text">6.4 训练设置</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E4%B8%8E%E5%88%86%E6%9E%90"><span class="nav-number">7.</span> <span class="nav-text">7. 实验结果与分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#7-1-%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8E%E7%8E%AF%E5%A2%83"><span class="nav-number">7.1.</span> <span class="nav-text">7.1 数据集与环境</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-2-%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE"><span class="nav-number">7.2.</span> <span class="nav-text">7.2 实验设置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-3-%E5%AE%9A%E9%87%8F%E8%AF%84%E4%BC%B0"><span class="nav-number">7.3.</span> <span class="nav-text">7.3 定量评估</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-4-%E5%AE%9A%E6%80%A7%E8%AF%84%E4%BC%B0"><span class="nav-number">7.4.</span> <span class="nav-text">7.4 定性评估</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-5-%E5%BA%94%E7%94%A8%E4%BB%BB%E5%8A%A1"><span class="nav-number">7.5.</span> <span class="nav-text">7.5 应用任务</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#8-%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6"><span class="nav-number">8.</span> <span class="nav-text">8. 计算复杂度</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#9-%E7%BB%93%E8%AE%BA"><span class="nav-number">9.</span> <span class="nav-text">9. 结论</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">MaJianyu</p><div class="site-description" itemprop="description">永远相信，美好的事情即将发生。</div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">29</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">9</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">52</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/majianyu2007" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;majianyu2007" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/600064036" title="BiliBili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;600064036" rel="noopener me" target="_blank"><i class="fa-brands fa-bilibili fa-fw"></i>BiliBili</a></span></div><div class="cc-license animated" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://mjy.js.org/2025/12/18/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20%20TCSVT%202025%20%20T%C2%B2EA%EF%BC%9A%E7%9B%AE%E6%A0%87%E6%84%9F%E7%9F%A5%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80%E8%BF%91%E4%BC%BC%E7%BD%91%E7%BB%9C%E3%80%91/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="MaJianyu"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="TranquilYu's Blog"><meta itemprop="description" content="永远相信，美好的事情即将发生。"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="【论文阅读 | TCSVT 2025 | T²EA：目标感知泰勒展开近似网络】 | TranquilYu's Blog"><meta itemprop="description" content="T²EA：Target-Aware Taylor Expansion Approximation Network for Infrared &amp; Visible Fusion"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">【论文阅读 | TCSVT 2025 | T²EA：目标感知泰勒展开近似网络】</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2025-12-18 08:00:00" itemprop="dateCreated datePublished" datetime="2025-12-18T08:00:00+08:00">2025-12-18</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2025-12-21 09:12:45" itemprop="dateModified" datetime="2025-12-21T09:12:45+08:00">2025-12-21</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a> </span></span><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>24k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>43 分钟</span></span></div><div class="post-description">T²EA：Target-Aware Taylor Expansion Approximation Network for Infrared & Visible Fusion</div></div></header><div class="post-body" itemprop="articleBody"><p><img data-src="/./../images/image-20251221071909426.png" alt="image-20251221071909426"></p><p>题目：T²EA: Target-Aware Taylor Expansion Approximation Network for Infrared and Visible Image Fusion</p><p>期刊：IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), Vol.35, No.5, 2025</p><p>论文链接：<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/10819442">T2EA: Target-Aware Taylor Expansion Approximation Network for Infrared and Visible Image Fusion | IEEE Journals &amp; Magazine | IEEE Xplore</a></p><p>代码：<a target="_blank" rel="noopener" href="https://github.com/MysterYxby/T2EA">MysterYxby&#x2F;T2EA</a></p><p>年份：2025</p><h1 id="1-研究背景与动机"><a href="#1-研究背景与动机" class="headerlink" title="1. 研究背景与动机"></a>1. 研究背景与动机</h1><h2 id="1-1-红外-可见光融合的需求"><a href="#1-1-红外-可见光融合的需求" class="headerlink" title="1.1 红外-可见光融合的需求"></a>1.1 红外-可见光融合的需求</h2><ul><li>红外：低照&#x2F;遮挡&#x2F;恶劣天气下仍能突出目标，但纹理弱、分辨率低。</li><li>可见：纹理细节丰富，但受光照影响大。</li><li>目标：生成兼具“目标显著 + 场景纹理”的融合图，兼顾人眼观测与下游检测&#x2F;分割。</li></ul><h2 id="1-2-现有方法局限"><a href="#1-2-现有方法局限" class="headerlink" title="1.2 现有方法局限"></a>1.2 现有方法局限</h2><ul><li>规则式&#x2F;多尺度：可解释但策略固定，场景适应性差。</li><li>端到端深度：特征强但偏“黑箱”，易忽略梯度&#x2F;结构一致性，目标保持不足。</li><li>缺口：亟需“可解释 + 可学习”的统一框架，显式建模强度与高阶导并注入目标感知。</li></ul><h2 id="1-3-本文贡献"><a href="#1-3-本文贡献" class="headerlink" title="1.3 本文贡献"></a>1.3 本文贡献</h2><ol><li><strong>目标感知泰勒展开近似（TEA）</strong>：用多阶导显式刻画纹理与形状，可解释、可控。</li><li><strong>双分支特征融合 (DBFF)</strong>：按泰勒阶分别融合IR&#x2F;VIS特征，CBAM关注目标区域。</li><li><strong>逆泰勒重构 + 分割联合优化</strong>：保持导数一致性，分割梯度反哺融合，强化目标呈现。</li><li>在MSRS&#x2F;TNO&#x2F;LLVIP数据集及分割&#x2F;检测任务上验证，兼顾跨域泛化与任务友好性。</li></ol><hr><h1 id="2-整体框架"><a href="#2-整体框架" class="headerlink" title="2. 整体框架"></a>2. 整体框架</h1><p><img data-src="/./../images/image-20251221072301509.png" alt="image-20251221072301509"></p><p>输入IR&#x2F;VIS → 泰勒展开近似网络（TEA）分解 → 分阶双分支特征融合网络（DBFF网络）特征融合 → 逆泰勒展开（ITE）网络重构 →分割头联合优化（利用语义分割网络对融合图像进行细化）</p><p>核心即 <strong>“分解-融合-重构” + 目标梯度监督</strong>。</p><p><strong>损失函数</strong>：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi>J</mi><mi>o</mi><mi>i</mi><mi>n</mi><mi>t</mi></mrow></msub><mo>=</mo><msub><mi>L</mi><mi>F</mi></msub><mo>+</mo><mi>μ</mi><msub><mi>L</mi><mrow><mi>s</mi><mi>e</mi><mi>m</mi><mi>a</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{Joint} = L_{F} + \mu L_{semantic}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3283em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.09618em">J</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">in</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3283em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">F</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.8778em;vertical-align:-.1944em"></span><span class="mord mathnormal">μ</span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">se</span><span class="mord mathnormal mtight">man</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span><p>该公式结合了融合损失（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>F</mi></msub></mrow><annotation encoding="application/x-tex">L_F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3283em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">F</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>）和语义分割损失（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>s</mi><mi>e</mi><mi>m</mi><mi>a</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{semantic}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">se</span><span class="mord mathnormal mtight">man</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>），通过平衡这两者优化网络性能。</p><hr><h1 id="3-泰勒展开近似（TEA）网络"><a href="#3-泰勒展开近似（TEA）网络" class="headerlink" title="3. 泰勒展开近似（TEA）网络"></a>3. 泰勒展开近似（TEA）网络</h1><p>代码来自 <code>network/TEM.py</code>、<code>loss/Taylor.py</code>、<code>train_TEM.py</code>。</p><p><img data-src="/./../images/image-20251221081723587.png" alt="image-20251221081723587"></p><h2 id="3-1-泰勒展开理论"><a href="#3-1-泰勒展开理论" class="headerlink" title="3.1 泰勒展开理论"></a>3.1 泰勒展开理论</h2><p>泰勒展开是数学中用于将函数在某一点处展开的一个工具。在图像处理中，可以利用泰勒展开对图像进行特征提取。假设图像可以用函数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> 表示，泰勒展开的表达式如下：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo>+</mo><msup><mi>f</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo>⋅</mo><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mfrac><mrow><msup><mi>f</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo></mrow><mrow><mn>2</mn><mo stretchy="false">!</mo></mrow></mfrac><mo>⋅</mo><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><msub><mi>x</mi><mn>0</mn></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo>⋯</mo><mo>+</mo><mfrac><mrow><msup><mi>f</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo></mrow><mrow><mi>n</mi><mo stretchy="false">!</mo></mrow></mfrac><mo>⋅</mo><mo stretchy="false">(</mo><mi>x</mi><mo>−</mo><msub><mi>x</mi><mn>0</mn></msub><msup><mo stretchy="false">)</mo><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">f(x) = f(x_0) + f&#x27;(x_0) \cdot (x - x_0) + \frac{f&#x27;&#x27;(x_0)}{2!} \cdot (x - x_0)^2 + \cdots + \frac{f^{(n)}(x_0)}{n!} \cdot (x - x_0)^n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1.0519em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8019em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:2.1149em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4289em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span><span class="mclose">!</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.7519em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.6667em;vertical-align:-.0833em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:2.251em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.565em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">n</span><span class="mclose">!</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.888em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.7144em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span></span><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> 表示原始图像，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x_0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 是基础特征层，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><msup><mi>f</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>…</mo></mrow><annotation encoding="application/x-tex">f&#x27;(x_0), f&#x27;&#x27;(x_0), \dots</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.7519em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.7519em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="minner">…</span></span></span></span> 表示不同阶次的导数特征。通过这种分解方法，能够提取图像的全局结构（低频信息）和细节（高频信息）。</p><p>对应代码（泰勒项的生成与阶乘系数累加）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># network/TEM.py</span></span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> factorial  <span class="comment"># 引入阶乘用于泰勒系数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, n</span>):  <span class="comment"># 前向：生成各阶泰勒项</span></span><br><span class="line">    y_list = []  <span class="comment"># 保存每一阶特征</span></span><br><span class="line">    x = <span class="variable language_">self</span>.base(<span class="built_in">input</span>)  <span class="comment"># 计算基础层 f(x0)</span></span><br><span class="line">    y_list.append(x)  <span class="comment"># 记录0阶项</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n + <span class="number">1</span>):  <span class="comment"># 逐阶生成导数特征</span></span><br><span class="line">        y_list.append(<span class="variable language_">self</span>.gradient(torch.cat([y_list[i - <span class="number">1</span>], <span class="built_in">input</span>], dim=<span class="number">1</span>)))  <span class="comment"># 拼接上一阶与输入</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y_list)):  <span class="comment"># 按阶累加泰勒项</span></span><br><span class="line">        result += (<span class="number">1</span> / factorial(i)) * y_list[i]  <span class="comment"># 1/i! 权重累加到结果</span></span><br></pre></td></tr></table></figure><h2 id="3-2-网络架构与实现"><a href="#3-2-网络架构与实现" class="headerlink" title="3.2 网络架构与实现"></a>3.2 网络架构与实现</h2><p>根据泰勒展开公式，TEA 网络包括两大主要部分：基础层的提取和导数层的提取。网络分别由<strong>映射网络</strong>和<strong>导数网络</strong>组成。</p><h3 id="3-2-1-映射网络"><a href="#3-2-1-映射网络" class="headerlink" title="3.2.1 映射网络"></a>3.2.1 映射网络</h3><p>映射网络的作用是提取图像的基础层特征，即泰勒展开的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x_0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。该网络由卷积层和残差模块（ResBlock）构成，具体结构如下：</p><ul><li>卷积层：一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7278em;vertical-align:-.0833em"></span><span class="mord">5</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">5</span></span></span></span>的卷积核。</li><li>残差模块：由多个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1 \times 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7278em;vertical-align:-.0833em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">1</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3 \times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7278em;vertical-align:-.0833em"></span><span class="mord">3</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">3</span></span></span></span>卷积层构成，用于提取全局信息，防止大尺度细节丢失。</li></ul><p>对应代码（基础层<code>base</code> 与ResB）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># network/TEM.py</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResB</span>(nn.Module):  <span class="comment"># 残差模块</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_c, out_c</span>):  <span class="comment"># 初始化输入/输出通道</span></span><br><span class="line">        <span class="built_in">super</span>(ResB, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        <span class="variable language_">self</span>.Res = nn.Sequential(  <span class="comment"># 主分支卷积序列</span></span><br><span class="line">            nn.Conv2d(in_c, out_c, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>),  <span class="comment"># 1x1调整通道</span></span><br><span class="line">            nn.LeakyReLU(),  <span class="comment"># 非线性激活</span></span><br><span class="line">            nn.Conv2d(out_c, out_c, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),  <span class="comment"># 3x3提取局部</span></span><br><span class="line">            nn.LeakyReLU(),  <span class="comment"># 非线性激活</span></span><br><span class="line">            nn.Conv2d(out_c, out_c, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>),  <span class="comment"># 1x1融合特征</span></span><br><span class="line">        )  <span class="comment"># 主分支结束</span></span><br><span class="line">        <span class="variable language_">self</span>.Conv = nn.Conv2d(in_c, out_c, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>)  <span class="comment"># shortcut 1x1</span></span><br><span class="line">        <span class="variable language_">self</span>.activate = nn.LeakyReLU()  <span class="comment"># 残差后激活</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        y = <span class="variable language_">self</span>.Res(x) + <span class="variable language_">self</span>.Conv(x)  <span class="comment"># 主分支与shortcut相加</span></span><br><span class="line">        y = <span class="variable language_">self</span>.activate(y)  <span class="comment"># 激活输出</span></span><br><span class="line">        <span class="keyword">return</span> y  <span class="comment"># 返回残差结果</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Taylor_Encoder</span>(nn.Module):  <span class="comment"># TEA编码器主体</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:  <span class="comment"># 初始化</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        <span class="variable language_">self</span>.base = nn.Sequential(  <span class="comment"># 基础层分支</span></span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),  <span class="comment"># 5x5卷积提取低频</span></span><br><span class="line">            nn.LeakyReLU(),  <span class="comment"># 激活</span></span><br><span class="line">            ResB(<span class="number">32</span>, <span class="number">64</span>),  <span class="comment"># ResB扩大通道</span></span><br><span class="line">            ResB(<span class="number">64</span>, <span class="number">32</span>),  <span class="comment"># ResB压回通道</span></span><br><span class="line">            ResB(<span class="number">32</span>, <span class="number">1</span>),  <span class="comment"># ResB输出到1通道</span></span><br><span class="line">        )  <span class="comment"># 基础分支结束</span></span><br></pre></td></tr></table></figure><h3 id="3-2-2-导数网络"><a href="#3-2-2-导数网络" class="headerlink" title="3.2.2 导数网络"></a>3.2.2 导数网络</h3><p>导数网络的目的是通过多阶泰勒展开提取图像的高阶特征（即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><msup><mi>f</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>…</mo></mrow><annotation encoding="application/x-tex">f&#x27;(x_0), f&#x27;&#x27;(x_0), \dots</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.7519em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.7519em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="minner">…</span></span></span></span>）。该网络由两个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">5 \times 5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7278em;vertical-align:-.0833em"></span><span class="mord">5</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">5</span></span></span></span>卷积层和三个残差模块（ResDBlocks）组成，采用Mish激活函数和密集连接来保留细节特征。在图像特征的提取中，每一阶导数不仅依赖于前一阶的特征，还与基础层（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x_0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>）以及上层导数特征（如<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f&#x27;(x_0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.7519em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>）相关。为了保持这些特征之间的高相关性，网络通过拼接基础层特征和导数层特征来递归提取各阶特征。</p><p>例如，对于泰勒展开的第一阶导数，将输入图像特征和上一阶（基础层或更低阶的导数）特征进行拼接，送入网络进行进一步的处理，以确保各阶导数层的准确提取。通过这种方式，网络能够有效提取图像的全局结构与局部细节。</p><p>此过程中的重要机制是拼接操作（Concatenate），它通过将低阶导数和输入图像的特征结合，从而为高阶导数提供更完整的上下文信息。</p><p>对应代码（Mish激活 + RDBLOCK + gradient分支）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># network/TEM.py</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Conv</span>(nn.Module):  <span class="comment"># 基础卷积块</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_c, o_c, size, stride</span>):  <span class="comment"># 输入/输出通道与核大小</span></span><br><span class="line">        <span class="built_in">super</span>(Conv, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(  <span class="comment"># 卷积层</span></span><br><span class="line">            in_channels=in_c,  <span class="comment"># 输入通道数</span></span><br><span class="line">            out_channels=o_c,  <span class="comment"># 输出通道数</span></span><br><span class="line">            kernel_size=size,  <span class="comment"># 卷积核尺寸</span></span><br><span class="line">            stride=stride,  <span class="comment"># 步长</span></span><br><span class="line">            padding=size // <span class="number">2</span>,  <span class="comment"># 保持尺寸的填充</span></span><br><span class="line">        )  <span class="comment"># 卷积层结束</span></span><br><span class="line">        <span class="variable language_">self</span>.activation = nn.Mish()  <span class="comment"># Mish激活</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        x = <span class="variable language_">self</span>.conv(<span class="built_in">input</span>)  <span class="comment"># 卷积计算</span></span><br><span class="line">        y = <span class="variable language_">self</span>.activation(x)  <span class="comment"># Mish激活</span></span><br><span class="line">        <span class="keyword">return</span> y  <span class="comment"># 输出特征</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RDBLOCK</span>(nn.Module):  <span class="comment"># 残差密集连接块</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, outchannel</span>):  <span class="comment"># 基础通道数</span></span><br><span class="line">        <span class="built_in">super</span>(RDBLOCK, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = Conv(in_c=outchannel, o_c=outchannel, size=<span class="number">1</span>, stride=<span class="number">1</span>)  <span class="comment"># 1x1特征</span></span><br><span class="line">        <span class="variable language_">self</span>.conv2 = Conv(in_c=<span class="number">2</span> * outchannel, o_c=outchannel, size=<span class="number">3</span>, stride=<span class="number">1</span>)  <span class="comment"># 3x3融合</span></span><br><span class="line">        <span class="variable language_">self</span>.conv3 = Conv(in_c=<span class="number">3</span> * outchannel, o_c=outchannel, size=<span class="number">1</span>, stride=<span class="number">1</span>)  <span class="comment"># 1x1压缩</span></span><br><span class="line">        <span class="variable language_">self</span>.conv4 = Conv(in_c=<span class="number">4</span> * outchannel, o_c=<span class="number">2</span> * outchannel, size=<span class="number">1</span>, stride=<span class="number">1</span>)  <span class="comment"># 1x1扩展</span></span><br><span class="line">        <span class="variable language_">self</span>.shortcut = nn.Sequential(  <span class="comment"># shortcut分支</span></span><br><span class="line">            nn.Conv2d(in_channels=outchannel, out_channels=<span class="number">2</span> * outchannel, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>)  <span class="comment"># 1x1对齐</span></span><br><span class="line">        )  <span class="comment"># shortcut结束</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        x1 = <span class="variable language_">self</span>.conv1(x)  <span class="comment"># 第1层</span></span><br><span class="line">        y = torch.cat((x, x1), <span class="number">1</span>)  <span class="comment"># 拼接x与x1</span></span><br><span class="line">        x2 = <span class="variable language_">self</span>.conv2(y)  <span class="comment"># 第2层</span></span><br><span class="line">        z = torch.cat((x, x1, x2), <span class="number">1</span>)  <span class="comment"># 拼接到更密集特征</span></span><br><span class="line">        x3 = <span class="variable language_">self</span>.conv3(z)  <span class="comment"># 第3层</span></span><br><span class="line">        x4 = <span class="variable language_">self</span>.conv4(torch.cat((z, x3), <span class="number">1</span>))  <span class="comment"># 第4层并再拼接</span></span><br><span class="line">        output = <span class="variable language_">self</span>.shortcut(x) + x4  <span class="comment"># 残差相加</span></span><br><span class="line">        output = F.mish(output)  <span class="comment"># Mish激活</span></span><br><span class="line">        <span class="keyword">return</span> output  <span class="comment"># 输出特征</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Taylor_Encoder</span>(nn.Module):  <span class="comment"># TEA编码器主体</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:  <span class="comment"># 初始化</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        <span class="variable language_">self</span>.gradient = nn.Sequential(  <span class="comment"># 导数分支</span></span><br><span class="line">            nn.Conv2d(<span class="number">2</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),  <span class="comment"># 5x5卷积提取导数特征</span></span><br><span class="line">            nn.LeakyReLU(),  <span class="comment"># 激活</span></span><br><span class="line">            RDBLOCK(<span class="number">8</span>),  <span class="comment"># RDBLOCK保持细节</span></span><br><span class="line">            RDBLOCK(<span class="number">16</span>),  <span class="comment"># 通道逐级扩展</span></span><br><span class="line">            RDBLOCK(<span class="number">32</span>),  <span class="comment"># 更深层密集连接</span></span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),  <span class="comment"># 5x5回到1通道</span></span><br><span class="line">            nn.LeakyReLU(),  <span class="comment"># 激活</span></span><br><span class="line">        )  <span class="comment"># 导数分支结束</span></span><br></pre></td></tr></table></figure><h3 id="3-2-3-网络架构"><a href="#3-2-3-网络架构" class="headerlink" title="3.2.3 网络架构"></a>3.2.3 网络架构</h3><p>根据泰勒展开公式，需要同时估算基础层 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x_0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 和各阶导数层 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mtext> </mtext><mo stretchy="false">(</mo><mi>k</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">]</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f^{(k)}(x_0) \ (k \in [1, n])</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.138em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.888em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace"> </span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">[</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord mathnormal">n</span><span class="mclose">])</span></span></span></span>。为了充分提取这些特征，可通过以下方式组合网络：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi mathvariant="normal">Φ</mi><mi>b</mi></msub><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi mathvariant="normal">Φ</mi><mi>d</mi></msub><mrow><mo fence="true">(</mo><mtext>Concat</mtext><mo stretchy="false">(</mo><msup><mi>f</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(x) = \Phi_b(f(x)) + \sum_{k=1}^{n} \Phi_d \left( \text{Concat}(f^{(k-1)}(x_0), f(x)) \right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord">Φ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:2.9535em;vertical-align:-1.3021em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em"><span style="top:-1.8479em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord">Φ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size2">(</span></span><span class="mord text"><span class="mord">Concat</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))</span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size2">)</span></span></span></span></span></span></span><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Φ</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">\Phi_b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord">Φ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 为映射网络，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Φ</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">\Phi_d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord">Φ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 为导数网络，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Concat</mtext></mrow><annotation encoding="application/x-tex">\text{Concat}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord text"><span class="mord">Concat</span></span></span></span></span> 表示将基础层和各阶导数层特征进行拼接。</p><p>对应代码（base + gradient + concat + 累加）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># network/TEM.py</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, n</span>):  <span class="comment"># 前向：组合基础层与导数层</span></span><br><span class="line">    y_list = []  <span class="comment"># 保存各阶特征</span></span><br><span class="line">    x = <span class="variable language_">self</span>.base(<span class="built_in">input</span>)  <span class="comment"># 基础层输出</span></span><br><span class="line">    y_list.append(x)  <span class="comment"># 加入0阶</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n + <span class="number">1</span>):  <span class="comment"># 生成1..n阶</span></span><br><span class="line">        y_list.append(<span class="variable language_">self</span>.gradient(torch.cat([y_list[i - <span class="number">1</span>], <span class="built_in">input</span>], dim=<span class="number">1</span>)))  <span class="comment"># concat并估计导数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y_list)):  <span class="comment"># 按阶累加</span></span><br><span class="line">        result += (<span class="number">1</span> / factorial(i)) * y_list[i]  <span class="comment"># 1/i! 加权</span></span><br><span class="line">    <span class="keyword">return</span> result, y_list  <span class="comment"># 返回重建结果与各阶项</span></span><br></pre></td></tr></table></figure><h3 id="3-2-4-损失函数"><a href="#3-2-4-损失函数" class="headerlink" title="3.2.4 损失函数"></a>3.2.4 损失函数</h3><p>在优化过程中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>p</mi><mi>i</mi><mi>x</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{pixel}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.9694em;vertical-align:-.2861em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span></span></span></span>负责控制重建的图像与源图像之间的像素级差异，而<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{grad}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.9694em;vertical-align:-.2861em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">g</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span></span></span></span>则强调图像中的细节特征。为了平衡这两者的影响，这里引入了超参数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6944em"></span><span class="mord mathnormal">λ</span></span></span></span>，它用于调整这两个损失项的权重。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6944em"></span><span class="mord mathnormal">λ</span></span></span></span>的合理选择对于优化过程至关重要，它决定了网络在保留全局信息（通过像素损失）和细节信息（通过梯度损失）之间的权衡。</p><p>在训练过程中，通过逐步调整<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6944em"></span><span class="mord mathnormal">λ</span></span></span></span>的值，可以帮助网络在保留图像整体结构的同时，增强细节的表现，尤其是在低对比度和高噪声的区域。</p><p>为了优化网络参数，作者采用了联合损失函数来训练 TEA 网络：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mi>T</mi></msub><mo>=</mo><msub><mi>L</mi><mrow><mi>p</mi><mi>i</mi><mi>x</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>+</mo><mi>λ</mi><msub><mi>L</mi><mrow><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_T = L_{pixel} + \lambda L_{grad}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3283em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.9694em;vertical-align:-.2861em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.9805em;vertical-align:-.2861em"></span><span class="mord mathnormal">λ</span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">g</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span></span></span></span></span><ul><li><p><strong>像素损失</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>p</mi><mi>i</mi><mi>x</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{pixel}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.9694em;vertical-align:-.2861em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span></span></span></span>：计算输入图像与网络输出图像在像素级的差异，用于保证图像重构的精度。</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi>p</mi><mi>i</mi><mi>x</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>H</mi><mi>W</mi></mrow></mfrac><mi mathvariant="normal">∥</mi><msub><mi>I</mi><mi>x</mi></msub><mo>−</mo><msub><mi>I</mi><mi>o</mi></msub><msub><mi mathvariant="normal">∥</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_{pixel} = \frac{1}{H W} \| I_x - I_o \|_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.9694em;vertical-align:-.2861em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:2.0074em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mord mathnormal" style="margin-right:.13889em">W</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">∥</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">I_x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">I_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 分别表示输入图像（红外或可见光图像）和输出图像。</p></li><li><p><strong>梯度细节损失</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{grad}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.9694em;vertical-align:-.2861em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">g</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span></span></span></span>：用于优化图像细节的保留，通过计算图像的梯度差异来增强细节。</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>H</mi><mi>W</mi></mrow></mfrac><mi mathvariant="normal">∥</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∇</mi><msub><mi>I</mi><mi>o</mi></msub><mi mathvariant="normal">∣</mi><mo>−</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∇</mi><msub><mi>I</mi><mi>x</mi></msub><mi mathvariant="normal">∣</mi><mo separator="true">,</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∇</mi><msub><mi>I</mi><mi>n</mi></msub><mi mathvariant="normal">∣</mi><mo stretchy="false">)</mo><msub><mi mathvariant="normal">∥</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_{grad} = \frac{1}{H W} \| |\nabla I_o| - \max (|\nabla I_x| , |\nabla I_n|) \|_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.9694em;vertical-align:-.2861em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">g</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:2.0074em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mord mathnormal" style="margin-right:.13889em">W</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">∥∣∇</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">∣∇</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">∣∇</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mclose">)</span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∇</mi></mrow><annotation encoding="application/x-tex">\nabla</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord">∇</span></span></span></span> 表示梯度操作，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∣</mi><mo>⋅</mo><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">|\cdot|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">∣</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">∣</span></span></span></span> 表示绝对值操作，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>max</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\max</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.4306em"></span><span class="mop">max</span></span></span></span> 表示取最大值，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">I_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 是导数网络提取的特征。</p></li></ul><p>对应代码（像素 L1 + 梯度损失 + derivative max聚合）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># loss/Taylor.py</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">L_Intensity</span>(nn.Module):  <span class="comment"># 像素L1损失</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image_A, image_B</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        Loss_intensity = F.l1_loss(image_A, image_B)  <span class="comment"># 计算L1差</span></span><br><span class="line">        <span class="keyword">return</span> Loss_intensity  <span class="comment"># 返回像素损失</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">L_Grad</span>(nn.Module):  <span class="comment"># 梯度损失</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image_A, image_B</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        image_A_Y = image_A[:, :<span class="number">1</span>, :, :]  <span class="comment"># 取A的Y通道</span></span><br><span class="line">        image_B_Y = image_B[:, :<span class="number">1</span>, :, :]  <span class="comment"># 取B的Y通道</span></span><br><span class="line">        gradient_A = <span class="variable language_">self</span>.sobelconv(image_A_Y)  <span class="comment"># Sobel梯度A</span></span><br><span class="line">        gradient_B = <span class="variable language_">self</span>.sobelconv(image_B_Y)  <span class="comment"># Sobel梯度B</span></span><br><span class="line">        Loss_gradient = F.l1_loss(gradient_A, gradient_B)  <span class="comment"># 梯度L1</span></span><br><span class="line">        <span class="keyword">return</span> Loss_gradient  <span class="comment"># 返回梯度损失</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Taylor_loss</span>(nn.Module):  <span class="comment"># 泰勒联合损失</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, result, gd</span>):  <span class="comment"># input为原图，gd为各阶导数</span></span><br><span class="line">        b, c, h, w = result.shape  <span class="comment"># 读取输出尺寸</span></span><br><span class="line">        grad_map = torch.zeros([b, c, h, w]).to(<span class="variable language_">self</span>.device)  <span class="comment"># 初始化梯度图</span></span><br><span class="line">        loss_L1 = <span class="variable language_">self</span>.<span class="built_in">int</span>(<span class="built_in">input</span>, result)   <span class="comment"># L_pixel：像素L1</span></span><br><span class="line">        loss_g1 = <span class="variable language_">self</span>.grad(<span class="built_in">input</span>, result)  <span class="comment"># 输出与输入梯度差</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(gd)):  <span class="comment"># 遍历导数阶次</span></span><br><span class="line">            grad_map = torch.<span class="built_in">max</span>(grad_map, gd[i])  <span class="comment"># 聚合各阶最大响应</span></span><br><span class="line">        loss_g2 = <span class="variable language_">self</span>.<span class="built_in">int</span>(<span class="variable language_">self</span>.sobelconv(<span class="built_in">input</span>), grad_map)  <span class="comment"># 梯度与导数最大图</span></span><br><span class="line">        loss_g = loss_g1 + <span class="number">0.3</span> * loss_g2  <span class="comment"># 梯度损失加权</span></span><br><span class="line">        <span class="keyword">return</span> loss_L1, loss_g, loss_L1 + loss_g  <span class="comment"># 返回分项与总损失</span></span><br></pre></td></tr></table></figure><h2 id="3-3-网络优化"><a href="#3-3-网络优化" class="headerlink" title="3.3 网络优化"></a>3.3 网络优化</h2><p>通过最小化上述损失函数，TEA 网络能够从红外和可见光图像中提取有效的特征，既保留了图像的整体结构，又能够细致地提取图像中的细节特征，为后续的图像融合和目标检测任务提供支持。</p><p>对应代码（训练中使用联合损失并反向传播优化）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train_TEM.py</span></span><br><span class="line">loss_int, loss_grad, loss = loss_ft(img, out, y)  <span class="comment"># 计算像素与梯度损失</span></span><br><span class="line">optimizer.zero_grad()  <span class="comment"># 清空梯度</span></span><br><span class="line">loss.backward()  <span class="comment"># 反向传播</span></span><br><span class="line">optimizer.step()  <span class="comment"># 更新参数</span></span><br></pre></td></tr></table></figure><hr><h1 id="4-双分支特征融合（DBFF）网络"><a href="#4-双分支特征融合（DBFF）网络" class="headerlink" title="4. 双分支特征融合（DBFF）网络"></a>4. 双分支特征融合（DBFF）网络</h1><p>代码来自 <code>network/FusionNet.py</code>、<code>loss/Fusion.py</code>、<code>train_Fusion.py</code>。</p><p><img data-src="/./../images/image-20251221081738903.png" alt="image-20251221081738903"></p><h2 id="4-1-网络架构概述"><a href="#4-1-网络架构概述" class="headerlink" title="4.1 网络架构概述"></a>4.1 网络架构概述</h2><p>双分支特征融合（DBFF）网络的核心目标是将分解得到的红外和可见光图像特征进行有效融合，从而生成高质量的融合图像。DBFF网络采用两条并行的分支结构，每条分支分别从红外图像和可见光图像中提取特征。每条分支的结构完全相同，具体包括卷积层和梯度残差密集块（GRDB）模块。通过这种结构，DBFF能够在多尺度上提取图像的浅层特征，并进行有效融合。</p><h3 id="4-1-1-双分支结构"><a href="#4-1-1-双分支结构" class="headerlink" title="4.1.1 双分支结构"></a>4.1.1 双分支结构</h3><p>在DBFF网络中，有两条并行的分支来分别处理红外图像和可见光图像。这两条分支具有相同的架构，通过卷积操作提取浅层特征，增强图像的局部细节。</p><ul><li><strong>卷积层</strong>：用于提取图像的基本特征。</li><li><strong>梯度残差密集块（GRDB）</strong>：GRDB是一种改进的残差模块，采用了密集连接和梯度残差网络，能够更好地保留细节信息并进行多尺度特征提取。</li></ul><p>对应代码（GRDB的实现：密集连接 + Sobel梯度残差）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># network/FusionNet.py</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvLeakyRelu2d</span>(nn.Module):  <span class="comment"># 基础卷积块</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=<span class="number">1</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span></span>):  <span class="comment"># 初始化超参</span></span><br><span class="line">        <span class="built_in">super</span>(ConvLeakyRelu2d, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride, dilation=dilation, groups=groups)  <span class="comment"># 卷积层</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        <span class="keyword">return</span> F.leaky_relu(<span class="variable language_">self</span>.conv(x), negative_slope=<span class="number">0.2</span>)  <span class="comment"># LeakyReLU 激活</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Sobelxy</span>(nn.Module):  <span class="comment"># Sobel 梯度模块</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=<span class="number">1</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span></span>):  <span class="comment"># 初始化超参</span></span><br><span class="line">        <span class="built_in">super</span>(Sobelxy, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        sobel_filter = np.array([[<span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>], [<span class="number">2</span>, <span class="number">0</span>, -<span class="number">2</span>], [<span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>]])  <span class="comment"># Sobel 核</span></span><br><span class="line">        <span class="variable language_">self</span>.convx = nn.Conv2d(channels, channels, kernel_size=kernel_size, padding=padding, stride=stride, dilation=dilation, groups=channels, bias=<span class="literal">False</span>)  <span class="comment"># x方向梯度</span></span><br><span class="line">        <span class="variable language_">self</span>.convx.weight.data.copy_(torch.from_numpy(sobel_filter))  <span class="comment"># 载入权重</span></span><br><span class="line">        <span class="variable language_">self</span>.convy = nn.Conv2d(channels, channels, kernel_size=kernel_size, padding=padding, stride=stride, dilation=dilation, groups=channels, bias=<span class="literal">False</span>)  <span class="comment"># y方向梯度</span></span><br><span class="line">        <span class="variable language_">self</span>.convy.weight.data.copy_(torch.from_numpy(sobel_filter.T))  <span class="comment"># 载入权重</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        sobelx = <span class="variable language_">self</span>.convx(x)  <span class="comment"># x方向梯度</span></span><br><span class="line">        sobely = <span class="variable language_">self</span>.convy(x)  <span class="comment"># y方向梯度</span></span><br><span class="line">        x = torch.<span class="built_in">abs</span>(sobelx) + torch.<span class="built_in">abs</span>(sobely)  <span class="comment"># 幅值叠加</span></span><br><span class="line">        <span class="keyword">return</span> x  <span class="comment"># 返回梯度特征</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Conv1</span>(nn.Module):  <span class="comment"># 1x1 卷积块</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, kernel_size=<span class="number">1</span>, padding=<span class="number">0</span>, stride=<span class="number">1</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span></span>):  <span class="comment"># 初始化超参</span></span><br><span class="line">        <span class="built_in">super</span>(Conv1, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride, dilation=dilation, groups=groups)  <span class="comment"># 1x1卷积</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.conv(x)  <span class="comment"># 返回卷积结果</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DenseBlock</span>(nn.Module):  <span class="comment"># 密集连接块</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, channels</span>):  <span class="comment"># 输入通道数</span></span><br><span class="line">        <span class="built_in">super</span>(DenseBlock, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = ConvLeakyRelu2d(channels, channels)  <span class="comment"># 第1层</span></span><br><span class="line">        <span class="variable language_">self</span>.conv2 = ConvLeakyRelu2d(<span class="number">2</span> * channels, channels)  <span class="comment"># 第2层</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        x = torch.cat((x, <span class="variable language_">self</span>.conv1(x)), dim=<span class="number">1</span>)  <span class="comment"># 拼接第1层输出</span></span><br><span class="line">        x = torch.cat((x, <span class="variable language_">self</span>.conv2(x)), dim=<span class="number">1</span>)  <span class="comment"># 拼接第2层输出</span></span><br><span class="line">        <span class="keyword">return</span> x  <span class="comment"># 返回密集特征</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RGBD</span>(nn.Module):  <span class="comment"># 梯度残差密集块（GRDB 对应实现）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):  <span class="comment"># 输入/输出通道</span></span><br><span class="line">        <span class="built_in">super</span>(RGBD, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        <span class="variable language_">self</span>.dense = DenseBlock(in_channels)  <span class="comment"># 密集连接分支</span></span><br><span class="line">        <span class="variable language_">self</span>.convdown = Conv1(<span class="number">3</span> * in_channels, out_channels)  <span class="comment"># 通道压缩</span></span><br><span class="line">        <span class="variable language_">self</span>.sobelconv = Sobelxy(in_channels)  <span class="comment"># 梯度分支</span></span><br><span class="line">        <span class="variable language_">self</span>.convup = Conv1(in_channels, out_channels)  <span class="comment"># 通道对齐</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        x1 = <span class="variable language_">self</span>.dense(x)  <span class="comment"># 密集分支特征</span></span><br><span class="line">        x1 = <span class="variable language_">self</span>.convdown(x1)  <span class="comment"># 压缩通道</span></span><br><span class="line">        x2 = <span class="variable language_">self</span>.sobelconv(x)  <span class="comment"># 梯度分支特征</span></span><br><span class="line">        x2 = <span class="variable language_">self</span>.convup(x2)  <span class="comment"># 对齐通道</span></span><br><span class="line">        <span class="keyword">return</span> F.leaky_relu(x1 + x2, negative_slope=<span class="number">0.1</span>)  <span class="comment"># 残差融合后激活</span></span><br></pre></td></tr></table></figure><p>对应代码（双分支结构：红外&#x2F;可见光对称提取）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># network/FusionNet.py</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FusionNetwork</span>(nn.Module):  <span class="comment"># DBFF 主体</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, output</span>):  <span class="comment"># 初始化输出通道</span></span><br><span class="line">        <span class="built_in">super</span>(FusionNetwork, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        vis_ch = [<span class="number">16</span>, <span class="number">32</span>, <span class="number">48</span>]  <span class="comment"># 可见光分支通道</span></span><br><span class="line">        inf_ch = [<span class="number">16</span>, <span class="number">32</span>, <span class="number">48</span>]  <span class="comment"># 红外分支通道</span></span><br><span class="line">        output = <span class="number">1</span>  <span class="comment"># 输出单通道</span></span><br><span class="line">        <span class="variable language_">self</span>.vis_conv = ConvLeakyRelu2d(<span class="number">1</span>, vis_ch[<span class="number">0</span>])  <span class="comment"># 可见光卷积层</span></span><br><span class="line">        <span class="variable language_">self</span>.vis_rgbd1 = RGBD(vis_ch[<span class="number">0</span>], vis_ch[<span class="number">1</span>])  <span class="comment"># 可见光 GRDB-1</span></span><br><span class="line">        <span class="variable language_">self</span>.vis_rgbd2 = RGBD(vis_ch[<span class="number">1</span>], vis_ch[<span class="number">2</span>])  <span class="comment"># 可见光 GRDB-2</span></span><br><span class="line">        <span class="variable language_">self</span>.inf_conv = ConvLeakyRelu2d(<span class="number">1</span>, inf_ch[<span class="number">0</span>])  <span class="comment"># 红外卷积层</span></span><br><span class="line">        <span class="variable language_">self</span>.inf_rgbd1 = RGBD(inf_ch[<span class="number">0</span>], inf_ch[<span class="number">1</span>])  <span class="comment"># 红外 GRDB-1</span></span><br><span class="line">        <span class="variable language_">self</span>.inf_rgbd2 = RGBD(inf_ch[<span class="number">1</span>], inf_ch[<span class="number">2</span>])  <span class="comment"># 红外 GRDB-2</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image_vis, image_ir</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        x_vis_origin = image_vis[:, :<span class="number">1</span>]  <span class="comment"># 提取可见光Y通道</span></span><br><span class="line">        x_inf_origin = image_ir  <span class="comment"># 红外单通道</span></span><br><span class="line">        x_vis_p = <span class="variable language_">self</span>.vis_conv(x_vis_origin)  <span class="comment"># 可见光浅层特征</span></span><br><span class="line">        x_vis_p1 = <span class="variable language_">self</span>.vis_rgbd1(x_vis_p)  <span class="comment"># 可见光 GRDB-1</span></span><br><span class="line">        x_vis_p2 = <span class="variable language_">self</span>.vis_rgbd2(x_vis_p1)  <span class="comment"># 可见光 GRDB-2</span></span><br><span class="line">        x_inf_p = <span class="variable language_">self</span>.inf_conv(x_inf_origin)  <span class="comment"># 红外浅层特征</span></span><br><span class="line">        x_inf_p1 = <span class="variable language_">self</span>.inf_rgbd1(x_inf_p)  <span class="comment"># 红外 GRDB-1</span></span><br><span class="line">        x_inf_p2 = <span class="variable language_">self</span>.inf_rgbd2(x_inf_p1)  <span class="comment"># 红外 GRDB-2</span></span><br></pre></td></tr></table></figure><h3 id="4-1-2-特征融合"><a href="#4-1-2-特征融合" class="headerlink" title="4.1.2 特征融合"></a>4.1.2 特征融合</h3><p>在两条分支分别提取出红外和可见光图像的特征后，将这两部分特征进行融合。融合操作采用了元素级加法，将提取的红外和可见光图像特征进行加和，得到融合后的特征图。这一步确保了图像的多模态信息能够被有效整合，从而增强了目标的突出显示和场景细节的保留。</p><p>对应代码（分支特征拼接 + CBAM + 解码融合）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># network/FusionNet.py</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FusionNetwork</span>(nn.Module):  <span class="comment"># DBFF 主体</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, output</span>):  <span class="comment"># 初始化输出通道</span></span><br><span class="line">        <span class="built_in">super</span>(FusionNetwork, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        vis_ch = [<span class="number">16</span>, <span class="number">32</span>, <span class="number">48</span>]  <span class="comment"># 可见光分支通道</span></span><br><span class="line">        inf_ch = [<span class="number">16</span>, <span class="number">32</span>, <span class="number">48</span>]  <span class="comment"># 红外分支通道</span></span><br><span class="line">        <span class="variable language_">self</span>.attention = cbam_block(vis_ch[<span class="number">2</span>] + inf_ch[<span class="number">2</span>])  <span class="comment"># CBAM 注意力</span></span><br><span class="line">        <span class="variable language_">self</span>.decode4 = ConvBnLeakyRelu2d(vis_ch[<span class="number">2</span>] + inf_ch[<span class="number">2</span>], vis_ch[<span class="number">1</span>] + vis_ch[<span class="number">1</span>], padding=<span class="number">3</span>, dilation=<span class="number">3</span>)  <span class="comment"># 解码层</span></span><br><span class="line">        <span class="variable language_">self</span>.decode3 = ConvBnLeakyRelu2d(vis_ch[<span class="number">1</span>] + inf_ch[<span class="number">1</span>], vis_ch[<span class="number">0</span>] + inf_ch[<span class="number">0</span>], padding=<span class="number">3</span>, dilation=<span class="number">3</span>)  <span class="comment"># 解码层</span></span><br><span class="line">        <span class="variable language_">self</span>.decode2 = ConvBnLeakyRelu2d(vis_ch[<span class="number">0</span>] + inf_ch[<span class="number">0</span>], vis_ch[<span class="number">0</span>], padding=<span class="number">3</span>, dilation=<span class="number">3</span>)  <span class="comment"># 解码层</span></span><br><span class="line">        <span class="variable language_">self</span>.decode1 = ConvBnTanh2d(vis_ch[<span class="number">0</span>], output)  <span class="comment"># 输出层</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image_vis, image_ir</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        x_attention = <span class="variable language_">self</span>.attention(torch.cat((x_vis_p2, x_inf_p2), dim=<span class="number">1</span>))  <span class="comment"># 特征拼接后做注意力</span></span><br><span class="line">        x = <span class="variable language_">self</span>.decode4(x_attention)  <span class="comment"># 解码融合</span></span><br><span class="line">        x = <span class="variable language_">self</span>.decode3(x)  <span class="comment"># 逐级解码</span></span><br><span class="line">        x = <span class="variable language_">self</span>.decode2(x)  <span class="comment"># 逐级解码</span></span><br><span class="line">        x = <span class="variable language_">self</span>.decode1(x)  <span class="comment"># 输出融合图</span></span><br><span class="line">        <span class="keyword">return</span> x  <span class="comment"># 返回融合结果</span></span><br></pre></td></tr></table></figure><h3 id="4-1-3-注意力机制"><a href="#4-1-3-注意力机制" class="headerlink" title="4.1.3 注意力机制"></a>4.1.3 注意力机制</h3><p>为了进一步增强特征融合效果，作者在DBFF网络中引入了注意力机制。具体而言，采用了空间-通道注意力机制（CBAM）来优化特征融合的过程。CBAM通过在空间和通道维度上对特征图进行加权处理，能够有效抑制背景信息，突出目标区域，从而提高融合图像的质量。</p><p>对应代码（CBAM：通道注意力 + 空间注意力）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># network/FusionNet.py</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChannelAttention</span>(nn.Module):  <span class="comment"># 通道注意力</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_planes, ratio=<span class="number">8</span></span>):  <span class="comment"># 输入通道与压缩比</span></span><br><span class="line">        <span class="built_in">super</span>(ChannelAttention, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        <span class="variable language_">self</span>.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)  <span class="comment"># 全局平均池化</span></span><br><span class="line">        <span class="variable language_">self</span>.max_pool = nn.AdaptiveMaxPool2d(<span class="number">1</span>)  <span class="comment"># 全局最大池化</span></span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Conv2d(in_planes, in_planes // ratio, <span class="number">1</span>, bias=<span class="literal">False</span>)  <span class="comment"># 降维</span></span><br><span class="line">        <span class="variable language_">self</span>.relu1 = nn.ReLU()  <span class="comment"># ReLU</span></span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Conv2d(in_planes // ratio, in_planes, <span class="number">1</span>, bias=<span class="literal">False</span>)  <span class="comment"># 升维</span></span><br><span class="line">        <span class="variable language_">self</span>.sigmoid = nn.Sigmoid()  <span class="comment"># Sigmoid 归一化</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        avg_out = <span class="variable language_">self</span>.fc2(<span class="variable language_">self</span>.relu1(<span class="variable language_">self</span>.fc1(<span class="variable language_">self</span>.avg_pool(x))))  <span class="comment"># 平均池化分支</span></span><br><span class="line">        max_out = <span class="variable language_">self</span>.fc2(<span class="variable language_">self</span>.relu1(<span class="variable language_">self</span>.fc1(<span class="variable language_">self</span>.max_pool(x))))  <span class="comment"># 最大池化分支</span></span><br><span class="line">        out = avg_out + max_out  <span class="comment"># 分支相加</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.sigmoid(out)  <span class="comment"># 输出通道权重</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SpatialAttention</span>(nn.Module):  <span class="comment"># 空间注意力</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, kernel_size=<span class="number">7</span></span>):  <span class="comment"># 卷积核大小</span></span><br><span class="line">        <span class="built_in">super</span>(SpatialAttention, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        <span class="keyword">assert</span> kernel_size <span class="keyword">in</span> (<span class="number">3</span>, <span class="number">7</span>), <span class="string">&#x27;kernel size must be 3 or 7&#x27;</span>  <span class="comment"># 约束核尺寸</span></span><br><span class="line">        padding = <span class="number">3</span> <span class="keyword">if</span> kernel_size == <span class="number">7</span> <span class="keyword">else</span> <span class="number">1</span>  <span class="comment"># 设置padding</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">2</span>, <span class="number">1</span>, kernel_size, padding=padding, bias=<span class="literal">False</span>)  <span class="comment"># 空间卷积</span></span><br><span class="line">        <span class="variable language_">self</span>.sigmoid = nn.Sigmoid()  <span class="comment"># Sigmoid 归一化</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        avg_out = torch.mean(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)  <span class="comment"># 通道平均</span></span><br><span class="line">        max_out, _ = torch.<span class="built_in">max</span>(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)  <span class="comment"># 通道最大</span></span><br><span class="line">        x = torch.cat([avg_out, max_out], dim=<span class="number">1</span>)  <span class="comment"># 拼接两路</span></span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)  <span class="comment"># 空间卷积</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.sigmoid(x)  <span class="comment"># 输出空间权重</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">cbam_block</span>(nn.Module):  <span class="comment"># CBAM 组合块</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, channel, ratio=<span class="number">8</span>, kernel_size=<span class="number">7</span></span>):  <span class="comment"># 初始化超参</span></span><br><span class="line">        <span class="built_in">super</span>(cbam_block, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        <span class="variable language_">self</span>.channelattention = ChannelAttention(channel, ratio=ratio)  <span class="comment"># 通道注意力</span></span><br><span class="line">        <span class="variable language_">self</span>.spatialattention = SpatialAttention(kernel_size=kernel_size)  <span class="comment"># 空间注意力</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        x = x * <span class="variable language_">self</span>.channelattention(x)  <span class="comment"># 通道加权</span></span><br><span class="line">        x = x * <span class="variable language_">self</span>.spatialattention(x)  <span class="comment"># 空间加权</span></span><br><span class="line">        <span class="keyword">return</span> x  <span class="comment"># 返回加权特征</span></span><br></pre></td></tr></table></figure><h2 id="4-2-损失函数"><a href="#4-2-损失函数" class="headerlink" title="4.2 损失函数"></a>4.2 损失函数</h2><p>双分支结构是DBFF网络的核心，旨在分别处理红外图像和可见光图像的特征。每个分支采用相同的网络架构，包括卷积层和梯度残差密集块（GRDB），以便在多个尺度上提取图像的浅层特征。</p><p>在两条并行分支中，红外和可见光图像被独立地处理，提取出各自的特征。然后，利用加权融合策略，将这两部分特征进行融合，最终得到更具代表性的融合图像。与传统的单分支结构不同，DBFF网络通过引入注意力机制，能够更精细地处理红外图像中的低光区域和可见光图像中的细节部分，极大提升了图像的质量。</p><p>为了优化DBFF网络，确保其能够有效融合红外和可见光图像的特征，作者设计了一个联合损失函数，该损失函数包括强度损失和纹理细节损失两个部分：</p><h3 id="4-2-1-强度损失（Intensity-Loss）"><a href="#4-2-1-强度损失（Intensity-Loss）" class="headerlink" title="4.2.1 强度损失（Intensity Loss）"></a>4.2.1 强度损失（Intensity Loss）</h3><p>强度损失 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>i</mi><mi>n</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{int}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 主要用于约束融合图像的整体强度，使其与源图像在强度上保持一致。其公式为：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi>i</mi><mi>n</mi><mi>t</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>H</mi><mi>W</mi></mrow></mfrac><mi mathvariant="normal">∥</mi><msub><mi>I</mi><mi>f</mi></msub><mo>−</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>I</mi><mi>r</mi></msub><mo separator="true">,</mo><msub><mi>I</mi><mrow><mi>v</mi><mi>i</mi><mi>s</mi></mrow></msub><mo stretchy="false">)</mo><msub><mi mathvariant="normal">∥</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_{int} = \frac{1}{H W} \| I_f - \max(I_r, I_{vis}) \|_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:2.0074em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mord mathnormal" style="margin-right:.13889em">W</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">∥</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.10764em">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">v</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">I_f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.9694em;vertical-align:-.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.10764em">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span></span></span></span> 表示融合后的图像，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">I_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><mrow><mi>v</mi><mi>i</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">I_{vis}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">v</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 分别表示红外图像和可见光图像，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi></mrow><annotation encoding="application/x-tex">H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.13889em">W</span></span></span></span> 分别是图像的高度和宽度。</p><h3 id="4-2-2-纹理细节损失（Texture-Loss）"><a href="#4-2-2-纹理细节损失（Texture-Loss）" class="headerlink" title="4.2.2 纹理细节损失（Texture Loss）"></a>4.2.2 纹理细节损失（Texture Loss）</h3><p>纹理细节损失 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>t</mi><mi>e</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{tex}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2806em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 主要用于保留图像中的细节信息，尤其是图像中的边缘和纹理。其公式为：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi>t</mi><mi>e</mi><mi>x</mi></mrow></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>H</mi><mi>W</mi></mrow></mfrac><mi mathvariant="normal">∥</mi><mi mathvariant="normal">∇</mi><msub><mi>I</mi><mi>f</mi></msub><mo>−</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="normal">∇</mi><msub><mi>I</mi><mi>r</mi></msub><mo separator="true">,</mo><mi mathvariant="normal">∇</mi><msub><mi>I</mi><mrow><mi>v</mi><mi>i</mi><mi>s</mi></mrow></msub><mo stretchy="false">)</mo><msub><mi mathvariant="normal">∥</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_{tex} = \frac{1}{H W} \| \nabla I_f - \max(\nabla I_r, \nabla I_{vis}) \|_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2806em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:2.0074em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mord mathnormal" style="margin-right:.13889em">W</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">∥∇</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.10764em">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">∇</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">∇</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">v</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∇</mi></mrow><annotation encoding="application/x-tex">\nabla</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord">∇</span></span></span></span> 表示图像的梯度操作，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∇</mi><msub><mi>I</mi><mi>f</mi></msub><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">|\nabla I_f|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-.2861em"></span><span class="mord">∣∇</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.10764em">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span><span class="mord">∣</span></span></span></span> 表示融合图像的梯度，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="normal">∇</mi><msub><mi>I</mi><mi>r</mi></msub><mo separator="true">,</mo><mi mathvariant="normal">∇</mi><msub><mi>I</mi><mrow><mi>v</mi><mi>i</mi><mi>s</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\max(\nabla I_r, \nabla I_{vis})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">∇</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">∇</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">v</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 表示红外和可见光图像的梯度的最大值。</p><h3 id="4-2-3-总损失函数"><a href="#4-2-3-总损失函数" class="headerlink" title="4.2.3 总损失函数"></a>4.2.3 总损失函数</h3><p>联合损失函数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>F</mi></msub></mrow><annotation encoding="application/x-tex">L_F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3283em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">F</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 由强度损失和纹理细节损失组成，其公式为：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mi>F</mi></msub><mo>=</mo><msub><mi>L</mi><mrow><mi>i</mi><mi>n</mi><mi>t</mi></mrow></msub><mo>+</mo><mi>α</mi><msub><mi>L</mi><mrow><mi>t</mi><mi>e</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_F = L_{int} + \alpha L_{tex}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3283em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">F</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord mathnormal" style="margin-right:.0037em">α</span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2806em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.4306em"></span><span class="mord mathnormal" style="margin-right:.0037em">α</span></span></span></span> 是一个超参数，用于平衡强度损失和纹理细节损失的影响。</p><p>对应代码（强度与纹理梯度损失）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># loss/Fusion.py</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Sobelxy</span>(nn.Module):  <span class="comment"># Sobel 梯度</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  <span class="comment"># 初始化</span></span><br><span class="line">        <span class="built_in">super</span>(Sobelxy, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        kernelx = [[-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>], [-<span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>], [-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]]  <span class="comment"># x方向核</span></span><br><span class="line">        kernely = [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [-<span class="number">1</span>, -<span class="number">2</span>, -<span class="number">1</span>]]  <span class="comment"># y方向核</span></span><br><span class="line">        kernelx = torch.FloatTensor(kernelx).unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>)  <span class="comment"># 转Tensor</span></span><br><span class="line">        kernely = torch.FloatTensor(kernely).unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>)  <span class="comment"># 转Tensor</span></span><br><span class="line">        <span class="variable language_">self</span>.device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)  <span class="comment"># 设备</span></span><br><span class="line">        <span class="variable language_">self</span>.weightx = nn.Parameter(data=kernelx, requires_grad=<span class="literal">False</span>).to(<span class="variable language_">self</span>.device)  <span class="comment"># 固定权重x</span></span><br><span class="line">        <span class="variable language_">self</span>.weighty = nn.Parameter(data=kernely, requires_grad=<span class="literal">False</span>).to(<span class="variable language_">self</span>.device)  <span class="comment"># 固定权重y</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># 前向传播</span></span><br><span class="line">        sobelx = F.conv2d(x, <span class="variable language_">self</span>.weightx, padding=<span class="number">1</span>)  <span class="comment"># x方向梯度</span></span><br><span class="line">        sobely = F.conv2d(x, <span class="variable language_">self</span>.weighty, padding=<span class="number">1</span>)  <span class="comment"># y方向梯度</span></span><br><span class="line">        <span class="keyword">return</span> torch.<span class="built_in">abs</span>(sobelx) + torch.<span class="built_in">abs</span>(sobely)  <span class="comment"># 幅值叠加</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Fusionloss</span>(nn.Module):  <span class="comment"># 融合损失</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  <span class="comment"># 初始化</span></span><br><span class="line">        <span class="built_in">super</span>(Fusionloss, <span class="variable language_">self</span>).__init__()  <span class="comment"># 调用父类初始化</span></span><br><span class="line">        <span class="variable language_">self</span>.sobelconv = Sobelxy()  <span class="comment"># 梯度算子</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image_vis, image_ir, generate_img</span>):  <span class="comment"># 前向传播损失</span></span><br><span class="line">        image_y = image_vis[:, :<span class="number">1</span>, :, :]  <span class="comment"># 可见光Y通道</span></span><br><span class="line">        x_in_max = torch.<span class="built_in">max</span>(image_y, image_ir)  <span class="comment"># 强度目标：max(Ir,Ivis)</span></span><br><span class="line">        loss_in = F.l1_loss(x_in_max, generate_img)  <span class="comment"># 强度损失</span></span><br><span class="line">        y_grad = <span class="variable language_">self</span>.sobelconv(image_y)  <span class="comment"># 可见光梯度</span></span><br><span class="line">        ir_grad = <span class="variable language_">self</span>.sobelconv(image_ir)  <span class="comment"># 红外梯度</span></span><br><span class="line">        generate_img_grad = <span class="variable language_">self</span>.sobelconv(generate_img)  <span class="comment"># 融合图梯度</span></span><br><span class="line">        x_grad_joint = torch.<span class="built_in">max</span>(y_grad, ir_grad)  <span class="comment"># 梯度目标：max(grad)</span></span><br><span class="line">        loss_grad = F.l1_loss(x_grad_joint, generate_img_grad)  <span class="comment"># 纹理细节损失</span></span><br><span class="line">        loss_total = loss_in + <span class="number">10</span> * loss_grad  <span class="comment"># 总损失（含权重）</span></span><br><span class="line">        <span class="keyword">return</span> loss_in, loss_grad, loss_total  <span class="comment"># 返回分项与总损失</span></span><br></pre></td></tr></table></figure><h2 id="4-3-网络优化"><a href="#4-3-网络优化" class="headerlink" title="4.3 网络优化"></a>4.3 网络优化</h2><p>通过最小化上述损失函数，DBFF 网络能够在红外图像和可见光图像的特征之间找到最佳的融合方式。具体来说，网络会自动调整每个通道的权重，确保图像的亮度和细节得到合理的保留和增强。使用这种优化方法，DBFF 网络能够生成具有高质量细节和目标突出性的融合图像，适合后续的目标检测和图像分割任务。</p><p>对应代码（训练中计算融合损失并反向传播）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train_Fusion.py</span></span><br><span class="line">_, ir_y = Net(ir, <span class="number">2</span>)  <span class="comment"># 生成红外泰勒分解特征</span></span><br><span class="line">_, vis_y = Net(vis, <span class="number">2</span>)  <span class="comment"># 生成可见光泰勒分解特征</span></span><br><span class="line">result = Model(ir_y, vis_y)  <span class="comment"># DBFF 融合输出</span></span><br><span class="line">loss_int, loss_grad, loss = loss_ft(ir, vis, result)  <span class="comment"># 计算融合损失</span></span><br><span class="line">optimizer.zero_grad()  <span class="comment"># 清空梯度</span></span><br><span class="line">loss.backward()  <span class="comment"># 反向传播</span></span><br><span class="line">optimizer.step()  <span class="comment"># 更新参数</span></span><br></pre></td></tr></table></figure><h2 id="4-4-网络总结"><a href="#4-4-网络总结" class="headerlink" title="4.4 网络总结"></a>4.4 网络总结</h2><p>DBFF 网络通过双分支架构、注意力机制和优化损失函数，有效地融合了红外和可见光图像的多模态特征。该网络能够保持高质量的目标突出和图像细节，在多个视觉任务中表现出色，特别是在低光照和复杂场景中的目标检测和分割任务。</p><hr><h1 id="5-语义分割与目标优化"><a href="#5-语义分割与目标优化" class="headerlink" title="5. 语义分割与目标优化"></a>5. 语义分割与目标优化</h1><h2 id="5-1-语义分割网络"><a href="#5-1-语义分割网络" class="headerlink" title="5.1 语义分割网络"></a>5.1 语义分割网络</h2><p>语义分割网络（IBisNet）是T²EA网络的一个关键模块，它利用融合图像的高质量特征来优化目标检测和分割的效果。IBisNet通过专门设计的分割头，将图像中的各个目标区域提取出来，从而提高目标分割的精度。尤其在融合图像中，IBisNet能够更好地处理低光照或遮挡区域，使得目标能够更准确地从复杂背景中分离出来。</p><p>通过联合训练，IBisNet不仅优化了分割精度，还进一步增强了融合图像中目标的突出性，确保了在实际应用中，目标检测和目标分割能够在较为复杂的场景下表现出色。</p><p>为了进一步优化融合图像的目标突出性，采用<strong>IBisNet</strong>（改进版的双分支分割网络）进行训练。该网络通过语义分割来细化图像的目标区域，使得目标更易于检测和分割。</p><h2 id="5-2-损失函数"><a href="#5-2-损失函数" class="headerlink" title="5.2 损失函数"></a>5.2 损失函数</h2><p>联合损失函数包含<strong>融合损失</strong>（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>F</mi></msub></mrow><annotation encoding="application/x-tex">L_F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3283em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">F</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>）和<strong>语义分割损失</strong>（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>s</mi><mi>e</mi><mi>m</mi><mi>a</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{semantic}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">se</span><span class="mord mathnormal mtight">man</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>），以优化目标检测和分割任务。</p><hr><h1 id="6-任务联合优化（目标感知）"><a href="#6-任务联合优化（目标感知）" class="headerlink" title="6. 任务联合优化（目标感知）"></a>6. 任务联合优化（目标感知）</h1><h2 id="6-1-思路"><a href="#6-1-思路" class="headerlink" title="6.1 思路"></a>6.1 思路</h2><p>冻结 TEA（Taylor.pt）与分割模型 BiSeNet，仅微调 FusionModel，使融合图同时满足物理一致性与分割友好性。</p><h2 id="6-2-损失函数"><a href="#6-2-损失函数" class="headerlink" title="6.2 损失函数"></a>6.2 损失函数</h2><p>实现：<code>FusionLoss</code> 依然做强度&#x2F;梯度最大对齐，<code>OhemCELoss</code> 在分割分支做难例采样，见<a href="T2EA/loss/Task.py">T2EA&#x2F;loss&#x2F;Task.py</a>：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="script">L</mi><mtext>fusion</mtext></msub><mo>=</mo><mi mathvariant="normal">∥</mi><mover accent="true"><mi>I</mi><mo>^</mo></mover><mo>−</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>I</mi><mrow><mi>v</mi><mi>i</mi><mi>s</mi></mrow></msub><mo separator="true">,</mo><msub><mi>I</mi><mrow><mi>i</mi><mi>r</mi></mrow></msub><mo stretchy="false">)</mo><msub><mi mathvariant="normal">∥</mi><mn>1</mn></msub><mo>+</mo><mn>10</mn><mi mathvariant="normal">∥</mi><mi>g</mi><mo stretchy="false">(</mo><mover accent="true"><mi>I</mi><mo>^</mo></mover><mo stretchy="false">)</mo><mo>−</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>I</mi><mrow><mi>v</mi><mi>i</mi><mi>s</mi></mrow></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>g</mi><mo stretchy="false">(</mo><msub><mi>I</mi><mrow><mi>i</mi><mi>r</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><msub><mi mathvariant="normal">∥</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal{L}_{\text{fusion}} = \|\hat I - \max(I_{vis}, I_{ir})\|_1 + 10\|g(\hat I)-\max(g(I_{vis}), g(I_{ir}))\|_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">fusion</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1.1968em;vertical-align:-.25em"></span><span class="mord">∥</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.9468em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:.07847em">I</span></span><span style="top:-3.2523em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.1389em"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">v</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1.1968em;vertical-align:-.25em"></span><span class="mord">10∥</span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.9468em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:.07847em">I</span></span><span style="top:-3.2523em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.1389em"><span class="mord">^</span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03588em">v</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">))</span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span><p>分割采用 OhemCELoss：主输出 (L_{\text{main}})，辅助输出 (L_{\text{aux}})。</p><h2 id="6-3-总损失与调度"><a href="#6-3-总损失与调度" class="headerlink" title="6.3 总损失与调度"></a>6.3 总损失与调度</h2><p><a href="T2EA/train_task.py">T2EA&#x2F;train_task.py</a> 中：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="script">L</mi><mtext>total</mtext></msub><mo>=</mo><msub><mi mathvariant="script">L</mi><mtext>fusion</mtext></msub><mo>+</mo><mtext>num</mtext><mtext> </mtext><mo fence="false" stretchy="true" minsize="1.2em" maxsize="1.2em">(</mo><msub><mi>L</mi><mtext>main</mtext></msub><mo>+</mo><mn>0.1</mn><mtext> </mtext><msub><mi>L</mi><mtext>aux</mtext></msub><mo fence="false" stretchy="true" minsize="1.2em" maxsize="1.2em">)</mo><mo separator="true">,</mo><mspace width="1em"><mtext>num</mtext><mo>=</mo><mrow><mo fence="true">⌊</mo><mfrac><mtext>epoch</mtext><mn>10</mn></mfrac><mo fence="true">⌋</mo></mrow><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{fusion}} + \text{num}\,\big(L_{\text{main}} + 0.1\,L_{\text{aux}}\big),\quad \text{num}=\left\lfloor\frac{\text{epoch}}{10}\right\rfloor+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">total</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.8333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">fusion</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-.35em"></span><span class="mord text"><span class="mord">num</span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3175em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">main</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-.35em"></span><span class="mord">0.1</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">aux</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="delimsizing size1">)</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:1em"></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord text"><span class="mord">num</span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-.95em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">⌊</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">10</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord">epoch</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">⌋</span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">1</span></span></span></span></span><p>epoch 递增的 num 提升任务监督权重，使融合先收敛后适配分割。</p><h2 id="6-4-训练设置"><a href="#6-4-训练设置" class="headerlink" title="6.4 训练设置"></a>6.4 训练设置</h2><p>50 epoch，Adam(lr&#x3D;1e-5)、batch&#x3D;2；MSRS 带标签训练&#x2F;验证；最佳融合 loss 保存 Fusion_Seg.pt。</p><p>端到端前向（train_task.py）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1) 生成融合亮度（冻结 TEA &amp; Seg）</span></span><br><span class="line">_, ir_y = Taylor(ir, <span class="number">2</span>); _, vis_y = Taylor(vis_y_channel, <span class="number">2</span>)</span><br><span class="line">fused_y = FusionModel(ir_y, vis_y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2) 拼回彩色送分割</span></span><br><span class="line">fused_rgb = YCrCb2RGB(cat(fused_y, Cb, Cr))</span><br><span class="line">pred_main, pred_aux = SegModel(fused_rgb)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3) 计算双任务损失</span></span><br><span class="line">loss_fusion = L_int + <span class="number">10</span> L_grad</span><br><span class="line">loss_seg = L_main + <span class="number">0.1</span> L_aux (OHEM)</span><br><span class="line">loss_total = loss_fusion + num * loss_seg</span><br></pre></td></tr></table></figure><p>这样梯度从分割头回传到 FusionModel，使“目标区域更亮&#x2F;更清晰”，而 TEA 的可解释分解保持冻结稳定。</p><hr><h1 id="7-实验结果与分析"><a href="#7-实验结果与分析" class="headerlink" title="7. 实验结果与分析"></a>7. 实验结果与分析</h1><h2 id="7-1-数据集与环境"><a href="#7-1-数据集与环境" class="headerlink" title="7.1 数据集与环境"></a>7.1 数据集与环境</h2><ul><li><strong>数据集</strong>：使用MSRS、TNO、LLVIP等公开数据集进行实验。</li><li><strong>环境</strong>：实验在Intel Xeon CPU、NVIDIA Tesla P100 GPU上运行，使用Pytorch框架进行实现。</li></ul><h2 id="7-2-实验设置"><a href="#7-2-实验设置" class="headerlink" title="7.2 实验设置"></a>7.2 实验设置</h2><p>网络在三个阶段进行训练：</p><ul><li><strong>Stage 1</strong>：训练TEA网络。</li><li><strong>Stage 2</strong>：训练DBFF网络，并固定TEA网络参数。</li><li><strong>Stage 3</strong>：联合训练TEA、DBFF和语义分割网络。</li></ul><h2 id="7-3-定量评估"><a href="#7-3-定量评估" class="headerlink" title="7.3 定量评估"></a>7.3 定量评估</h2><p>实验结果显示，T²EA在多个量化指标（如SSIM、EN、VIF等）上均表现优异，相较于其他SOTA方法具有更强的细节保留和目标突出能力。</p><h2 id="7-4-定性评估"><a href="#7-4-定性评估" class="headerlink" title="7.4 定性评估"></a>7.4 定性评估</h2><p>通过视觉效果对比，T²EA能够有效突出目标，增强低对比度区域的细节，而其他方法则在某些场景下出现细节丢失或过度曝光。</p><h2 id="7-5-应用任务"><a href="#7-5-应用任务" class="headerlink" title="7.5 应用任务"></a>7.5 应用任务</h2><ul><li><strong>目标分割</strong>：IBisNet在T²EA融合图像上的分割精度优于其他方法，提供更准确的目标分割结果。</li><li><strong>目标检测</strong>：YOLOv5在T²EA融合图像上实现了更高的检测精度，尤其在低对比度和小目标检测中表现突出。</li></ul><h1 id="8-计算复杂度"><a href="#8-计算复杂度" class="headerlink" title="8. 计算复杂度"></a>8. 计算复杂度</h1><p>T²EA网络的计算复杂度相较于一些轻量级模型（如LRRNet）稍高，但考虑到其在目标检测和分割任务中的优异表现，这种计算代价是可以接受的。</p><h1 id="9-结论"><a href="#9-结论" class="headerlink" title="9. 结论"></a>9. 结论</h1><p>本研究提出的T²EA网络，通过目标感知的泰勒展开近似方法，在红外和可见光图像融合中取得了显著的改进，尤其在目标检测和图像分割任务中表现优异。T²EA能够有效保留细节、突出目标，并适应复杂的视觉任务，是一种有潜力的图像融合方法。</p></div><footer class="post-footer"><div class="post-copyright"><ul><li class="post-copyright-author"><strong>本文作者： </strong>MaJianyu</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://mjy.js.org/2025/12/18/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20%20TCSVT%202025%20%20T%C2%B2EA%EF%BC%9A%E7%9B%AE%E6%A0%87%E6%84%9F%E7%9F%A5%E6%B3%B0%E5%8B%92%E5%B1%95%E5%BC%80%E8%BF%91%E4%BC%BC%E7%BD%91%E7%BB%9C%E3%80%91/" title="【论文阅读 | TCSVT 2025 | T²EA：目标感知泰勒展开近似网络】">https://mjy.js.org/2025/12/18/【论文阅读 TCSVT 2025 T²EA：目标感知泰勒展开近似网络】/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="post-tags"><a href="/tags/%E7%BA%A2%E5%A4%96%E5%8F%AF%E8%A7%81%E5%85%89%E8%9E%8D%E5%90%88/" rel="tag"># 红外可见光融合</a> <a href="/tags/Taylor%E5%B1%95%E5%BC%80/" rel="tag"># Taylor展开</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%84%9F%E7%9F%A5/" rel="tag"># 目标感知</a> <a href="/tags/%E5%8F%8C%E5%88%86%E6%94%AF%E8%9E%8D%E5%90%88/" rel="tag"># 双分支融合</a> <a href="/tags/%E5%88%86%E5%89%B2%E8%81%94%E5%90%88%E4%BC%98%E5%8C%96/" rel="tag"># 分割联合优化</a></div><div class="post-nav"><div class="post-nav-item"><a href="/2025/12/17/oral-english-test/" rel="prev" title="英语口语测试备考"><i class="fa fa-angle-left"></i> 英语口语测试备考</a></div><div class="post-nav-item"></div></div></footer></article></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; 2021 – <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">MaJianyu</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span>站点总字数：</span> <span title="站点总字数">319k</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span>站点阅读时长 &asymp;</span> <span title="站点阅读时长">9:41</span></span></div><div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动</div><a href="https://icp.gov.moe/?keyword=20216556" target="_blank">萌ICP备20216556号</a></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div><div class="sidebar-dimmer"></div><div class="back-to-top" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up fa-lg"></i> <span>0%</span></div><a href="https://github.com/majianyu2007" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script src="https://mjy.js.org/js/darkmode@1.5.7.min.js"></script><script>var options = {
  bottom: '16px',
  right: '16px',
  left: 'unset',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();</script></body></html>
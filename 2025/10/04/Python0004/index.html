<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 8.0.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous" defer></script><script class="next-config" data-name="main" type="application/json">{"hostname":"mjy.js.org","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.25.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":"ture","style":"default"},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script><meta name="description" content="Pytorch教程"><meta property="og:type" content="article"><meta property="og:title" content="Python学习笔记其四"><meta property="og:url" content="https://mjy.js.org/2025/10/04/Python0004/index.html"><meta property="og:site_name" content="TranquilYu&#39;s Blog"><meta property="og:description" content="Pytorch教程"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://mjy.js.org/images/image-20251004141830767-1759558936645-3-1759559443801-13-1759559811461-26-1759559952609-43.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004141950553-1759558936645-4-1759559443802-14-1759559811461-27-1759559952609-44.png"><meta property="og:image" content="https://mjy.js.org/2025/10/04/images/b82a10c4-b278-4c9e-ad83-5556b675c1d9-1759559443802-15-1759559811462-28-1759559952609-45.png"><meta property="og:image" content="https://mjy.js.org/2025/10/04/images/d41bbdbc-216a-4374-bbf2-dfe1437e01df-1759559443802-16-1759559811462-31-1759559952609-47.png"><meta property="og:image" content="https://mjy.js.org/2025/10/04/images/79bf9f4a-fcce-4a9c-bc84-d69f787c2eee-1759559811462-30-1759559952609-46.png"><meta property="og:image" content="https://mjy.js.org/2025/10/04/images/606014d0-e40a-4c21-a18f-8824ac3a86ea-1759559811462-29-1759559952609-48.png"><meta property="og:image" content="https://mjy.js.org/2025/10/04/images/0a34c0d6-9627-4a65-a04e-82690727ee00-1759559811462-33-1759559952610-49.png"><meta property="og:image" content="https://mjy.js.org/2025/10/04/images/1c91f705-c38d-4025-9cbd-d6ebf25da8a0-1759559811462-32-1759559952610-50.png"><meta property="og:image" content="https://github.com/user-attachments/assets/05cb538b-2b11-4dde-8e29-efa19f27f0fc"><meta property="og:image" content="https://mjy.js.org/images/image-20251004144606392.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004144635260.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004144712104.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004144802053.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004144848041.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004145110419.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004145315803.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004145511592.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004145527681.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004145626056.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004151238326.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004151314736.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004151411703.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004151513660.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004151718462.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004151824370.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004155143064.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004155245827.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004155334340.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004155405152.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004155502079.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004155518151.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004155619357.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004155741508.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004155918237.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004160011322.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004160030493.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004160137783.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004160152624.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004160456282.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004160647088.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004160659944.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004160819065.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004160832338.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004161036193.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004161115819.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004161131582.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004161250282.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004161406034.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004161425662.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004161556149.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004161609676.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004161850169.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004161924416.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251004162126318.png"><meta property="article:published_time" content="2025-10-04T00:00:00.000Z"><meta property="article:modified_time" content="2025-10-18T07:05:08.351Z"><meta property="article:author" content="MaJianyu"><meta property="article:tag" content="Python"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://mjy.js.org/images/image-20251004141830767-1759558936645-3-1759559443801-13-1759559811461-26-1759559952609-43.png"><link rel="canonical" href="https://mjy.js.org/2025/10/04/Python0004/"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://mjy.js.org/2025/10/04/Python0004/","path":"2025/10/04/Python0004/","title":"Python学习笔记其四"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>Python学习笔记其四 | TranquilYu's Blog</title><script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous" defer></script><script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script><script src="/js/pjax.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.5.0/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script><script src="/js/third-party/search/local-search.js" defer></script><script src="/js/third-party/fancybox.js" defer></script><script src="/js/third-party/pace.js" defer></script><script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":"flase","tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src="/js/third-party/math/mathjax.js" defer></script><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" integrity="sha512-fHwaWebuwA7NSF5Qg/af4UeDx9XqUpYpOGgubo3yWu+b2IQR4UeQwbb42Ti7gVAjNtVoI/I9TEoYeu9omwcC6g==" crossorigin="anonymous" referrerpolicy="no-referrer"><link rel="alternate" href="/atom.xml" title="TranquilYu's Blog" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">TranquilYu's Blog</p><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Pytorch%E6%95%99%E7%A8%8B"><span class="nav-number">1.</span> <span class="nav-text">Pytorch教程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">1.1.</span> <span class="nav-text">搭建一个神经网络</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#PyTorch-%E5%B8%B8%E7%94%A8%E5%B1%82%E8%AE%B2%E8%A7%A3%E4%B8%8E%E7%A4%BA%E4%BE%8B"><span class="nav-number">2.</span> <span class="nav-text">PyTorch 常用层讲解与示例</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Linear-%E5%B1%82-%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82"><span class="nav-number">2.1.</span> <span class="nav-text">1. Linear 层 (全连接层)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Conv2d-%E5%B1%82-%E4%BA%8C%E7%BB%B4%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="nav-number">2.2.</span> <span class="nav-text">2. Conv2d 层 (二维卷积层)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#PyTorch-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3"><span class="nav-number">3.</span> <span class="nav-text">PyTorch 激活函数详解</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-ReLU"><span class="nav-number">3.1.</span> <span class="nav-text">1. ReLU</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Sigmoid"><span class="nav-number">3.2.</span> <span class="nav-text">2. Sigmoid</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Tanh"><span class="nav-number">3.3.</span> <span class="nav-text">3. Tanh</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-LeakyReLU"><span class="nav-number">3.4.</span> <span class="nav-text">4. LeakyReLU</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#PyTorch-%E5%B8%B8%E8%A7%81%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3"><span class="nav-number">4.</span> <span class="nav-text">PyTorch 常见损失函数详解</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-MSELoss%EF%BC%88%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AE%E6%8D%9F%E5%A4%B1%EF%BC%89"><span class="nav-number">4.1.</span> <span class="nav-text">1. MSELoss（均方误差损失）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-CrossEntropyLoss%EF%BC%88%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%EF%BC%89"><span class="nav-number">4.2.</span> <span class="nav-text">2. CrossEntropyLoss（交叉熵损失）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-KLDivLoss%EF%BC%88KL-%E6%95%A3%E5%BA%A6%E6%8D%9F%E5%A4%B1%EF%BC%89"><span class="nav-number">4.3.</span> <span class="nav-text">3. KLDivLoss（KL 散度损失）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#PyTorch-%E5%AE%B9%E5%99%A8%EF%BC%88Container%EF%BC%89%E8%AF%A6%E8%A7%A3"><span class="nav-number">5.</span> <span class="nav-text">PyTorch 容器（Container）详解</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8%E6%A8%A1%E5%9D%97"><span class="nav-number">6.</span> <span class="nav-text">优化器模块</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#PyTorch-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%9A-init-%E4%B8%8E-forward-%E6%96%B9%E6%B3%95%E8%AF%A6%E8%A7%A3"><span class="nav-number">7.</span> <span class="nav-text">PyTorch 神经网络基础：__init__ 与 forward 方法详解</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B"><span class="nav-number">7.1.</span> <span class="nav-text">1. 模型代码示例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E6%96%B9%E6%B3%95%E8%AF%A6%E8%A7%A3"><span class="nav-number">7.2.</span> <span class="nav-text">2. 方法详解</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-init-%E6%96%B9%E6%B3%95"><span class="nav-number">7.2.1.</span> <span class="nav-text">2.1 __init__ 方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-forward-%E6%96%B9%E6%B3%95"><span class="nav-number">7.2.2.</span> <span class="nav-text">2.2 forward 方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E6%95%B0%E6%8D%AE%E6%B5%81%E8%AF%B4%E6%98%8E"><span class="nav-number">7.3.</span> <span class="nav-text">3. 数据流说明</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E"><span class="nav-number">7.4.</span> <span class="nav-text">4. 补充说明</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#PyTorch-%E6%89%8B%E5%86%99%E4%BD%93%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E6%95%99%E5%AD%A6"><span class="nav-number">8.</span> <span class="nav-text">PyTorch 手写体图像识别教学</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E5%AF%BC%E5%85%A5%E5%BF%85%E8%A6%81%E5%BA%93"><span class="nav-number">8.1.</span> <span class="nav-text">1. 导入必要库</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E5%AE%9A%E4%B9%89%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">8.2.</span> <span class="nav-text">3. 定义前馈神经网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8"><span class="nav-number">8.3.</span> <span class="nav-text">4. 定义损失函数和优化器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="nav-number">8.4.</span> <span class="nav-text">5. 模型训练</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B"><span class="nav-number">8.4.1.</span> <span class="nav-text">训练流程:</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD-%E8%AE%A1%E7%AE%97%E9%A2%84%E6%B5%8B%E8%BE%93%E5%87%BA"><span class="nav-number">8.4.1.1.</span> <span class="nav-text">1. 前向传播: 计算预测输出</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E8%AE%A1%E7%AE%97%E6%8D%9F%E5%A4%B1"><span class="nav-number">8.4.1.2.</span> <span class="nav-text">2. 计算损失</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="nav-number">8.4.1.3.</span> <span class="nav-text">3. 反向传播</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0"><span class="nav-number">8.4.1.4.</span> <span class="nav-text">4. 参数更新</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-%E6%B5%8B%E8%AF%95%E6%A8%A1%E5%9E%8B%E5%87%86%E7%A1%AE%E7%8E%87"><span class="nav-number">8.5.</span> <span class="nav-text">6. 测试模型准确率</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD"><span class="nav-number">9.</span> <span class="nav-text">模型保存和加载</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9D%97"><span class="nav-number">10.</span> <span class="nav-text">计算机视觉模块</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2"><span class="nav-number">11.</span> <span class="nav-text">模型部署</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%95%A5%E8%AE%B2"><span class="nav-number">12.</span> <span class="nav-text">图像分类略讲</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">MaJianyu</p><div class="site-description" itemprop="description">永远相信，美好的事情即将发生。</div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">17</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">9</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">41</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/majianyu2007" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;majianyu2007" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/600064036" title="BiliBili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;600064036" rel="noopener me" target="_blank"><i class="fa-brands fa-bilibili fa-fw"></i>BiliBili</a></span></div><div class="cc-license animated" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://mjy.js.org/2025/10/04/Python0004/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="MaJianyu"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="TranquilYu's Blog"><meta itemprop="description" content="永远相信，美好的事情即将发生。"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="Python学习笔记其四 | TranquilYu's Blog"><meta itemprop="description" content="Pytorch教程"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Python学习笔记其四</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2025-10-04 08:00:00" itemprop="dateCreated datePublished" datetime="2025-10-04T08:00:00+08:00">2025-10-04</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2025-10-18 15:05:08" itemprop="dateModified" datetime="2025-10-18T15:05:08+08:00">2025-10-18</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a> </span></span><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>9.8k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>18 分钟</span></span></div><div class="post-description">Pytorch教程</div></div></header><div class="post-body" itemprop="articleBody"><h1 id="Pytorch教程"><a href="#Pytorch教程" class="headerlink" title="Pytorch教程"></a>Pytorch教程</h1><h2 id="搭建一个神经网络"><a href="#搭建一个神经网络" class="headerlink" title="搭建一个神经网络"></a>搭建一个神经网络</h2><p><img data-src="/./../images/image-20251004141830767-1759558936645-3-1759559443801-13-1759559811461-26-1759559952609-43.png" alt="image-20251004141830767"></p><p><img data-src="/./../images/image-20251004141950553-1759558936645-4-1759559443802-14-1759559811461-27-1759559952609-44.png" alt="image-20251004141950553"></p><h1 id="PyTorch-常用层讲解与示例"><a href="#PyTorch-常用层讲解与示例" class="headerlink" title="PyTorch 常用层讲解与示例"></a>PyTorch 常用层讲解与示例</h1><p>本教程介绍 PyTorch 中一些核心神经网络层：Linear、Conv2d、LSTM，包括它们的数学公式和对应实现代码。</p><hr><h2 id="1-Linear-层-全连接层"><a href="#1-Linear-层-全连接层" class="headerlink" title="1. Linear 层 (全连接层)"></a>1. Linear 层 (全连接层)</h2><img width="1920" height="1080" alt="image" data-src="./../images/b82a10c4-b278-4c9e-ad83-5556b675c1d9-1759559443802-15-1759559811462-28-1759559952609-45.png"><p><strong>数学公式</strong>：</p><p>输入向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><msub><mi>d</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub></msup></mrow><annotation encoding="application/x-tex">x \in \mathbb{R}^{d_{in}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.5782em;vertical-align:-.0391em"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.8491em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8491em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3281em"><span style="top:-2.357em;margin-left:0;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>，输出向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><msub><mi>d</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></msup></mrow><annotation encoding="application/x-tex">y \in \mathbb{R}^{d_{out}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7335em;vertical-align:-.1944em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.8491em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8491em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2963em"><span style="top:-2.357em;margin-left:0;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>=</mo><mi>x</mi><msup><mi>W</mi><mi mathvariant="normal">⊤</mi></msup><mo>+</mo><mi>b</mi><mo separator="true">,</mo><mspace width="1em"><mi>W</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>×</mo><msub><mi>d</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub></mrow></msup><mo separator="true">,</mo><mspace width="1em"><mi>b</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><msub><mi>d</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></msup></mrow><annotation encoding="application/x-tex">y = x W^\top + b, \quad W \in \mathbb{R}^{d_{out} \times d_{in}}, \quad b \in \mathbb{R}^{d_{out}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.1944em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.9824em;vertical-align:-.0833em"></span><span class="mord mathnormal">x</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8991em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.8889em;vertical-align:-.1944em"></span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:1em"></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord mathnormal" style="margin-right:.13889em">W</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1.0935em;vertical-align:-.1944em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8991em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2963em"><span style="top:-2.357em;margin-left:0;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3281em"><span style="top:-2.357em;margin-left:0;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:1em"></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.8991em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8991em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2963em"><span style="top:-2.357em;margin-left:0;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><p><strong>解释</strong>：</p><ul><li>每个输出节点是输入节点的加权和加上偏置</li><li>常用于全连接网络、MLP 等</li></ul><p><strong>示例代码</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearExample</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_in, d_out</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.linear = nn.Linear(d_in, d_out)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.linear(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例</span></span><br><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">10</span>)</span><br><span class="line">model_linear = LinearExample(<span class="number">10</span>, <span class="number">5</span>)</span><br><span class="line">y = model_linear(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Linear 输出形状:&quot;</span>, y.shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="2-Conv2d-层-二维卷积层"><a href="#2-Conv2d-层-二维卷积层" class="headerlink" title="2. Conv2d 层 (二维卷积层)"></a>2. Conv2d 层 (二维卷积层)</h2><img width="543" height="544" alt="image" data-src="./../images/d41bbdbc-216a-4374-bbf2-dfe1437e01df-1759559443802-16-1759559811462-31-1759559952609-47.png"><p><strong>数学公式</strong>：</p><p>输入张量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>×</mo><mi>H</mi><mo>×</mo><mi>W</mi></mrow></msup></mrow><annotation encoding="application/x-tex">X \in \mathbb{R}^{C_{in} \times H \times W}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7224em;vertical-align:-.0391em"></span><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.8413em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3281em"><span style="top:-2.357em;margin-left:-.0715em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:.08125em">H</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:.13889em">W</span></span></span></span></span></span></span></span></span></span></span></span>，卷积核 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>C</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>×</mo><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>×</mo><msub><mi>k</mi><mi>h</mi></msub><mo>×</mo><msub><mi>k</mi><mi>w</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">K \in \mathbb{R}^{C_{out} \times C_{in} \times k_h \times k_w}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7224em;vertical-align:-.0391em"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.8491em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8491em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2963em"><span style="top:-2.357em;margin-left:-.0715em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3281em"><span style="top:-2.357em;margin-left:-.0715em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3488em;margin-left:-.0315em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.1512em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1645em"><span style="top:-2.357em;margin-left:-.0315em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>Y</mi><mrow><mi>o</mi><mo separator="true">,</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>0</mn></mrow><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>−</mo><mn>1</mn></mrow></munderover><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>0</mn></mrow><mrow><msub><mi>k</mi><mi>h</mi></msub><mo>−</mo><mn>1</mn></mrow></munderover><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>0</mn></mrow><mrow><msub><mi>k</mi><mi>w</mi></msub><mo>−</mo><mn>1</mn></mrow></munderover><msub><mi>K</mi><mrow><mi>o</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mi>m</mi><mo separator="true">,</mo><mi>n</mi></mrow></msub><mo>⋅</mo><msub><mi>X</mi><mrow><mi>c</mi><mo separator="true">,</mo><mi>i</mi><mo>+</mo><mi>m</mi><mo separator="true">,</mo><mi>j</mi><mo>+</mo><mi>n</mi></mrow></msub><mo>+</mo><msub><mi>b</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">Y_{o,i,j} = \sum_{c=0}^{C_{in}-1} \sum_{m=0}^{k_h-1} \sum_{n=0}^{k_w-1} K_{o,c,m,n} \cdot X_{c,i+m,j+n} + b_o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.9694em;vertical-align:-.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.2222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:3.1201em;vertical-align:-1.2671em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8394em"><span style="top:-1.8829em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3111em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3281em"><span style="top:-2.357em;margin-left:-.0715em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.853em"><span style="top:-1.8829em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3169em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3488em;margin-left:-.0315em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.1512em"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8472em"><span style="top:-1.8829em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3111em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1645em"><span style="top:-2.357em;margin-left:-.0315em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:-.0715em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.9694em;vertical-align:-.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.0785em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">m</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.8444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.1514em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">o</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span><p><strong>解释</strong>：</p><ul><li>对每个输出通道，卷积核在输入各通道上进行加权求和，并加偏置</li><li>常用于图像特征提取、卷积神经网络</li></ul><p><strong>示例代码</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Conv2dExample</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, kernel_size</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(in_channels, out_channels, kernel_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.conv(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例</span></span><br><span class="line">x_img = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)  <span class="comment"># batch_size=2, 3通道, 32x32图像</span></span><br><span class="line">model_conv = Conv2dExample(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)  <span class="comment"># 输出6个通道, kernel 5x5</span></span><br><span class="line">y_img = model_conv(x_img)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Conv2d 输出形状:&quot;</span>, y_img.shape)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="PyTorch-激活函数详解"><a href="#PyTorch-激活函数详解" class="headerlink" title="PyTorch 激活函数详解"></a>PyTorch 激活函数详解</h1><p>本教程介绍常用激活函数。</p><hr><h2 id="1-ReLU"><a href="#1-ReLU" class="headerlink" title="1. ReLU"></a>1. ReLU</h2><img width="473" height="382" alt="image" data-src="./../images/79bf9f4a-fcce-4a9c-bc84-d69f787c2eee-1759559811462-30-1759559952609-46.png"><p>数学公式：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x) = \max(0, x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span><p>解释：</p><ul><li>将小于0的输入置0，大于0保持不变</li><li>计算简单，常用于卷积层或全连接层后</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">relu = nn.ReLU()</span><br><span class="line">x = torch.tensor([[-<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">2.0</span>]])</span><br><span class="line">y = relu(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;ReLU 输出:\n&quot;</span>, y)</span><br></pre></td></tr></table></figure><h2 id="2-Sigmoid"><a href="#2-Sigmoid" class="headerlink" title="2. Sigmoid"></a>2. Sigmoid</h2><img width="1920" height="1080" alt="image" data-src="./../images/606014d0-e40a-4c21-a18f-8824ac3a86ea-1759559811462-29-1759559952609-48.png"><p>数学公式：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\sigma(x) = \frac{1}{1 + e^{-x}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:2.0908em;vertical-align:-.7693em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.6973em"><span style="top:-2.989em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.7693em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><p>解释：</p><ul><li>将输入映射到 (0,1)</li><li>常用于二分类输出层</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">sigmoid = nn.Sigmoid()</span><br><span class="line">x = torch.tensor([[-<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">2.0</span>]])</span><br><span class="line">y = sigmoid(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Sigmoid 输出:\n&quot;</span>, y)</span><br></pre></td></tr></table></figure><h2 id="3-Tanh"><a href="#3-Tanh" class="headerlink" title="3. Tanh"></a>3. Tanh</h2><img width="425" height="234" alt="image" data-src="./../images/0a34c0d6-9627-4a65-a04e-82690727ee00-1759559811462-33-1759559952610-49.png"><p>数学公式：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>tanh</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msup><mi>e</mi><mi>x</mi></msup><mo>−</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow><mrow><msup><mi>e</mi><mi>x</mi></msup><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop">tanh</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:2.2177em;vertical-align:-.7693em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4483em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.5904em"><span style="top:-2.989em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.6973em"><span style="top:-2.989em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.6644em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.7713em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.7693em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><p>解释：</p><ul><li>将输入映射到 (-1, 1)</li><li>均值为 0，有助于训练收敛</li><li>常用于序列模型或隐藏层激活函数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">tanh = nn.Tanh()</span><br><span class="line">x = torch.tensor([[-<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">2.0</span>]])</span><br><span class="line">y = tanh(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Tanh 输出:\n&quot;</span>, y)</span><br></pre></td></tr></table></figure><h2 id="4-LeakyReLU"><a href="#4-LeakyReLU" class="headerlink" title="4. LeakyReLU"></a>4. LeakyReLU</h2><img width="683" height="559" alt="image" data-src="./../images/1c91f705-c38d-4025-9cbd-d6ebf25da8a0-1759559811462-32-1759559952610-50.png"><p>数学公式：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>x</mi><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>x</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>α</mi><mi>x</mi><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>x</mi><mo>≤</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow><mo separator="true">,</mo><mspace width="1em"><mi>α</mi><mo>=</mo><mn>0.01</mn></mrow><annotation encoding="application/x-tex">f(x) = \begin{cases} x, &amp; x &gt; 0 \\ \alpha x, &amp; x \le 0 \end{cases}, \quad \alpha = 0.01</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em"><span style="top:-3.69em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mpunct">,</span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord mathnormal">αx</span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em"><span style="top:-3.69em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:.2778em"></span><span class="mord">0</span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.008em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:.2778em"></span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:1em"></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord mathnormal" style="margin-right:.0037em">α</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">0.01</span></span></span></span></span><p>解释：</p><ul><li>避免 ReLU 的“死亡神经元”问题</li><li>对负值仍保留小梯度，不完全置零</li><li>常用于卷积层或全连接层激活函数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">leaky_relu = nn.LeakyReLU(negative_slope=<span class="number">0.01</span>)</span><br><span class="line">x = torch.tensor([[-<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">2.0</span>]])</span><br><span class="line">y = leaky_relu(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;LeakyReLU 输出:\n&quot;</span>, y)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="PyTorch-常见损失函数详解"><a href="#PyTorch-常见损失函数详解" class="headerlink" title="PyTorch 常见损失函数详解"></a>PyTorch 常见损失函数详解</h1><p>本教程介绍 PyTorch 中常用的损失函数，包括均方误差损失、交叉熵损失和 KL 散度损失，包含数学公式、原理解释和示例代码。</p><hr><h2 id="1-MSELoss（均方误差损失）"><a href="#1-MSELoss（均方误差损失）" class="headerlink" title="1. MSELoss（均方误差损失）"></a>1. MSELoss（均方误差损失）</h2><p>数学公式：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>MSELoss</mtext><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\text{MSELoss} = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord text"><span class="mord">MSELoss</span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">N</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8723em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.10903em">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.0359em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-.25em"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.1944em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.1944em"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.0359em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><p>解释：</p><ul><li>用于回归任务</li><li>衡量预测值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8889em;vertical-align:-.1944em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.1944em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.1944em"><span></span></span></span></span></span></span></span></span> 与真实值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.1944em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span></span></span></span> 的平方差</li><li>对异常值较敏感</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">mse_loss = nn.MSELoss()</span><br><span class="line">y_pred = torch.tensor([<span class="number">0.5</span>, <span class="number">0.8</span>, <span class="number">1.2</span>])</span><br><span class="line">y_true = torch.tensor([<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>])</span><br><span class="line">loss = mse_loss(y_pred, y_true)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MSELoss:&quot;</span>, loss.item())</span><br></pre></td></tr></table></figure><h2 id="2-CrossEntropyLoss（交叉熵损失）"><a href="#2-CrossEntropyLoss（交叉熵损失）" class="headerlink" title="2. CrossEntropyLoss（交叉熵损失）"></a>2. CrossEntropyLoss（交叉熵损失）</h2><p><strong>数学公式（多分类）</strong>：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>CrossEntropyLoss</mtext><mo>=</mo><mo>−</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><munderover><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>C</mi></munderover><msub><mi>y</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>c</mi></mrow></msub><mi>log</mi><mo>⁡</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mrow><mi>i</mi><mo separator="true">,</mo><mi>c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\text{CrossEntropyLoss} = - \frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{C} y_{i,c} \log \hat{y}_{i,c}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8778em;vertical-align:-.1944em"></span><span class="mord text"><span class="mord">CrossEntropyLoss</span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">N</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8723em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.10903em">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8829em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">C</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.0359em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.1944em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.1944em"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.0359em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span></span></span></span></span><p><strong>解释</strong>：</p><ul><li>用于分类任务</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">y_{i,c}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7167em;vertical-align:-.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:-.0359em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span></span></span></span> 是真实类别的 one-hot 编码，<img width="33" height="33" alt="image" data-src="https://github.com/user-attachments/assets/05cb538b-2b11-4dde-8e29-efa19f27f0fc"> 是预测概率</li><li>PyTorch 的 <code>CrossEntropyLoss</code> 内部包含 <code>Softmax</code>，不需要手动计算概率</li></ul><p><strong>示例代码</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">cross_entropy = nn.CrossEntropyLoss()</span><br><span class="line">y_pred = torch.tensor([[<span class="number">2.0</span>, <span class="number">1.0</span>, <span class="number">0.1</span>]])  <span class="comment"># logits</span></span><br><span class="line">y_true = torch.tensor([<span class="number">0</span>])                <span class="comment"># 类别索引</span></span><br><span class="line">loss = cross_entropy(y_pred, y_true)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;CrossEntropyLoss:&quot;</span>, loss.item())</span><br></pre></td></tr></table></figure><h2 id="3-KLDivLoss（KL-散度损失）"><a href="#3-KLDivLoss（KL-散度损失）" class="headerlink" title="3. KLDivLoss（KL 散度损失）"></a>3. KLDivLoss（KL 散度损失）</h2><p><strong>数学公式</strong>：</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>KLDivLoss</mtext><mo stretchy="false">(</mo><mi>P</mi><mo>∥</mo><mi>Q</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mi>i</mi></munder><mi>P</mi><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{KLDivLoss}(P \parallel Q) = \sum_i P(i) \log \frac{P(i)}{Q(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">KLDivLoss</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">∥</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">Q</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:2.7047em;vertical-align:-1.2777em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.8723em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span><span class="mspace" style="margin-right:.1667em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.936em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><p><strong>解释</strong>：</p><ul><li>用于衡量两个概率分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.13889em">P</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8778em;vertical-align:-.1944em"></span><span class="mord mathnormal">Q</span></span></span></span> 的差异</li><li>常用于知识蒸馏或概率分布拟合</li><li>PyTorch 要求输入为 <strong>log 概率</strong>（<code>log_target=False</code> 时输入为 log 概率）</li></ul><p><strong>示例代码</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">kl_div = nn.KLDivLoss(reduction=<span class="string">&#x27;batchmean&#x27;</span>)</span><br><span class="line">p = F.log_softmax(torch.tensor([[<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.3</span>]]), dim=<span class="number">1</span>)</span><br><span class="line">q = torch.tensor([[<span class="number">0.1</span>, <span class="number">0.6</span>, <span class="number">0.3</span>]])</span><br><span class="line">loss = kl_div(p, q)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;KLDivLoss:&quot;</span>, loss.item())</span><br></pre></td></tr></table></figure><h1 id="PyTorch-容器（Container）详解"><a href="#PyTorch-容器（Container）详解" class="headerlink" title="PyTorch 容器（Container）详解"></a>PyTorch 容器（Container）详解</h1><p>PyTorch 提供了一些容器类，用于组织和管理多个子模块，常用的有 <code>Sequential</code>、<code>ModuleList</code>、<code>ModuleDict</code>。</p><hr><p><strong>1. nn.Sequential</strong></p><ul><li>功能：将多个子模块按顺序组合成一个整体，前一个模块的输出作为下一个模块的输入</li><li>使用场景：简单的前向顺序网络，如 MLP 或简单 CNN</li></ul><p><strong>示例代码</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">model_seq = nn.Sequential(</span><br><span class="line">    nn.Linear(<span class="number">10</span>, <span class="number">20</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Linear(<span class="number">20</span>, <span class="number">5</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">10</span>)</span><br><span class="line">y = model_seq(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Sequential 输出形状:&quot;</span>, y.shape)</span><br></pre></td></tr></table></figure><p><strong>2. nn.ModuleList</strong></p><ul><li><strong>功能</strong>：保存任意数量的子模块的列表，但不会定义前向计算的顺序，需要在 <code>forward</code> 中手动调用</li><li><strong>使用场景</strong>：动态网络结构、多分支网络</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">layers = nn.ModuleList([nn.Linear(<span class="number">10</span>, <span class="number">10</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)])</span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> layers:</span><br><span class="line">    x = layer(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;ModuleList 输出形状:&quot;</span>, x.shape)</span><br></pre></td></tr></table></figure><p><strong>3. nn.ModuleDict</strong></p><ul><li><strong>功能</strong>：以字典形式保存子模块，便于按名字访问</li><li><strong>使用场景</strong>：多分支或命名网络结构</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">layer_dict = nn.ModuleDict(&#123;</span><br><span class="line">    <span class="string">&#x27;fc1&#x27;</span>: nn.Linear(<span class="number">10</span>, <span class="number">20</span>),</span><br><span class="line">    <span class="string">&#x27;relu&#x27;</span>: nn.ReLU(),</span><br><span class="line">    <span class="string">&#x27;fc2&#x27;</span>: nn.Linear(<span class="number">20</span>, <span class="number">5</span>)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">10</span>)</span><br><span class="line">x = layer_dict[<span class="string">&#x27;fc1&#x27;</span>](x)</span><br><span class="line">x = layer_dict[<span class="string">&#x27;relu&#x27;</span>](x)</span><br><span class="line">y = layer_dict[<span class="string">&#x27;fc2&#x27;</span>](x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;ModuleDict 输出形状:&quot;</span>, y.shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="优化器模块"><a href="#优化器模块" class="headerlink" title="优化器模块"></a>优化器模块</h1><p><img data-src="/./../images/image-20251004144606392.png" alt="image-20251004144606392"></p><p><img data-src="/./../images/image-20251004144635260.png" alt="image-20251004144635260"></p><p><img data-src="/./../images/image-20251004144712104.png" alt="image-20251004144712104"></p><p><img data-src="/./../images/image-20251004144802053.png" alt="image-20251004144802053"></p><p><img data-src="/./../images/image-20251004144848041.png" alt="image-20251004144848041"></p><p><img data-src="/./../images/image-20251004145110419.png" alt="image-20251004145110419"></p><p><img data-src="/./../images/image-20251004145315803.png" alt="image-20251004145315803"></p><p><img data-src="/./../images/image-20251004145511592.png" alt="image-20251004145511592"></p><p><img data-src="/./../images/image-20251004145527681.png" alt="image-20251004145527681"></p><p><img data-src="/./../images/image-20251004145626056.png" alt="image-20251004145626056"></p><h1 id="PyTorch-神经网络基础：-init-与-forward-方法详解"><a href="#PyTorch-神经网络基础：-init-与-forward-方法详解" class="headerlink" title="PyTorch 神经网络基础：__init__ 与 forward 方法详解"></a>PyTorch 神经网络基础：<code>__init__</code> 与 <code>forward</code> 方法详解</h1><p>在 PyTorch 中，自定义神经网络类通常继承自 <code>nn.Module</code>，核心方法是 <code>__init__</code> 和 <code>forward</code>。下面以一个简单的全连接网络为例进行讲解。</p><hr><h2 id="1-模型代码示例"><a href="#1-模型代码示例" class="headerlink" title="1. 模型代码示例"></a>1. 模型代码示例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleNN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="comment"># 定义网络结构</span></span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">28</span>*<span class="number">28</span>, <span class="number">128</span>)  <span class="comment"># 全连接层1</span></span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU()             <span class="comment"># 激活函数</span></span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">128</span>, <span class="number">10</span>)    <span class="comment"># 全连接层2</span></span><br><span class="line">        <span class="variable language_">self</span>.softmax = nn.Softmax(dim=<span class="number">1</span>) <span class="comment"># 输出概率归一化</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 前向计算流程</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>)  <span class="comment"># 展平输入为 (batch_size, 784)</span></span><br><span class="line">        x = <span class="variable language_">self</span>.fc1(x)        <span class="comment"># 第一个全连接层</span></span><br><span class="line">        x = <span class="variable language_">self</span>.relu(x)       <span class="comment"># ReLU 激活</span></span><br><span class="line">        x = <span class="variable language_">self</span>.fc2(x)        <span class="comment"># 第二个全连接层</span></span><br><span class="line">        x = <span class="variable language_">self</span>.softmax(x)    <span class="comment"># Softmax 转为概率分布</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型实例</span></span><br><span class="line">model = SimpleNN()</span><br></pre></td></tr></table></figure><h2 id="2-方法详解"><a href="#2-方法详解" class="headerlink" title="2. 方法详解"></a>2. 方法详解</h2><h3 id="2-1-init-方法"><a href="#2-1-init-方法" class="headerlink" title="2.1 __init__ 方法"></a>2.1 <code>__init__</code> 方法</h3><p><strong>作用</strong>：定义网络的各层，包括线性层、卷积层、激活函数等。</p><p><strong>特点</strong>：</p><ul><li>仅声明网络结构，不进行前向计算。</li><li>注册子模块，便于 PyTorch 自动管理参数。</li></ul><hr><h3 id="2-2-forward-方法"><a href="#2-2-forward-方法" class="headerlink" title="2.2 forward 方法"></a>2.2 <code>forward</code> 方法</h3><p><strong>作用</strong>：定义数据的前向传播流程。</p><p><strong>特点</strong>：</p><ul><li>输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.4306em"></span><span class="mord mathnormal">x</span></span></span></span> 会依次经过各个层，输出最终结果。</li><li>PyTorch 自动重载 <code>__call__</code> 方法，调用模型实例时会触发 <code>forward</code>。</li></ul><p><strong>示例</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output = model(input_tensor)</span><br></pre></td></tr></table></figure><ul><li>相当于执行：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.forward(input_tensor)</span><br></pre></td></tr></table></figure><ul><li>无需手动调用 forward 方法。</li></ul><h2 id="3-数据流说明"><a href="#3-数据流说明" class="headerlink" title="3. 数据流说明"></a>3. 数据流说明</h2><ol><li>输入图像张量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.4306em"></span><span class="mord mathnormal">x</span></span></span></span> 展平成 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mtext>batch size</mtext><mo separator="true">,</mo><mn>784</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\text{batch size}, 784)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord text"><span class="mord">batch size</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">784</span><span class="mclose">)</span></span></span></span>。</li><li>经过第一个全连接层 <code>fc1</code>，输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mtext>batch size</mtext><mo separator="true">,</mo><mn>128</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\text{batch size}, 128)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord text"><span class="mord">batch size</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">128</span><span class="mclose">)</span></span></span></span>。</li><li>通过 ReLU 激活函数，增加非线性。</li><li>经过第二个全连接层 <code>fc2</code>，输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mtext>batch size</mtext><mo separator="true">,</mo><mn>10</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\text{batch size}, 10)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord text"><span class="mord">batch size</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">10</span><span class="mclose">)</span></span></span></span>。</li><li>通过 Softmax 将输出转为概率分布，适合分类任务。</li></ol><p>这种结构是典型的全连接神经网络（MLP）分类模型。</p><p>这种结构是典型的全连接神经网络（MLP）分类模型。</p><h2 id="4-补充说明"><a href="#4-补充说明" class="headerlink" title="4. 补充说明"></a>4. 补充说明</h2><ul><li><code>nn.Linear(in_features, out_features)</code>：创建全连接层，将输入特征维度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>n</mi><mi mathvariant="normal">_</mi><mi>f</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>e</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">in\_features</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-.31em"></span><span class="mord mathnormal">in</span><span class="mord" style="margin-right:.02778em">_</span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">u</span><span class="mord mathnormal">res</span></span></span></span> 映射到输出维度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi><mi>u</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>f</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>e</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">out\_features</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-.31em"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord" style="margin-right:.02778em">_</span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">u</span><span class="mord mathnormal">res</span></span></span></span>。</li><li><code>nn.ReLU()</code>：激活函数，增加网络非线性能力。</li><li><code>nn.Softmax(dim=1)</code>：对指定维度做归一化，使输出值可以看作概率分布。</li><li><code>x.view(-1, 28*28)</code>：将输入张量展平成二维，<code>-1</code> 表示自动计算 batch size。</li><li>在 PyTorch 中，所有 <code>nn.Module</code> 的子模块都会自动注册为模型参数，无需手动管理。</li></ul><h1 id="PyTorch-手写体图像识别教学"><a href="#PyTorch-手写体图像识别教学" class="headerlink" title="PyTorch 手写体图像识别教学"></a>PyTorch 手写体图像识别教学</h1><hr><h2 id="1-导入必要库"><a href="#1-导入必要库" class="headerlink" title="1. 导入必要库"></a>1. 导入必要库</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 本教程演示如何使用 PyTorch 实现 MNIST 手写数字识别任务</span></span><br><span class="line"><span class="comment"># 包含数据加载、模型定义、训练和测试</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>#@ 2. 数据预处理与加载<br>MNIST 图片为 28x28 灰度图<br>需要将图片转换为张量并归一化到 [-1, 1]<br>DataLoader 按批次加载数据，并支持 shuffle 功能</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.5</span>,), (<span class="number">0.5</span>,))</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(test_dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h2 id="3-定义前馈神经网络"><a href="#3-定义前馈神经网络" class="headerlink" title="3. 定义前馈神经网络"></a>3. 定义前馈神经网络</h2><p>网络结构：<br>输入层: 28*28 &#x3D; 784 个神经元<br>隐藏层: 128 个神经元, ReLU 激活<br>输出层: 10 个神经元, Softmax 输出概率</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleNN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">28</span>*<span class="number">28</span>, <span class="number">128</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">128</span>, <span class="number">10</span>)</span><br><span class="line">        <span class="variable language_">self</span>.softmax = nn.Softmax(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>)  <span class="comment"># 展平</span></span><br><span class="line">        x = <span class="variable language_">self</span>.fc1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.relu(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.fc2(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.softmax(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = SimpleNN()</span><br></pre></td></tr></table></figure><h2 id="4-定义损失函数和优化器"><a href="#4-定义损失函数和优化器" class="headerlink" title="4. 定义损失函数和优化器"></a>4. 定义损失函数和优化器</h2><p>多分类交叉熵损失<br>优化器: 随机梯度下降 (SGD)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><h2 id="5-模型训练"><a href="#5-模型训练" class="headerlink" title="5. 模型训练"></a>5. 模型训练</h2><h3 id="训练流程"><a href="#训练流程" class="headerlink" title="训练流程:"></a>训练流程:</h3><h4 id="1-前向传播-计算预测输出"><a href="#1-前向传播-计算预测输出" class="headerlink" title="1. 前向传播: 计算预测输出"></a>1. 前向传播: 计算预测输出</h4><h4 id="2-计算损失"><a href="#2-计算损失" class="headerlink" title="2. 计算损失"></a>2. 计算损失</h4><h4 id="3-反向传播"><a href="#3-反向传播" class="headerlink" title="3. 反向传播"></a>3. 反向传播</h4><h4 id="4-参数更新"><a href="#4-参数更新" class="headerlink" title="4. 参数更新"></a>4. 参数更新</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> train_loader:</span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Loss: <span class="subst">&#123;running_loss/<span class="built_in">len</span>(train_loader):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="6-测试模型准确率"><a href="#6-测试模型准确率" class="headerlink" title="6. 测试模型准确率"></a>6. 测试模型准确率</h2><p>在测试集上评估模型性能</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        outputs = model(images)</span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        total += labels.size(<span class="number">0</span>)</span><br><span class="line">        correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Test Accuracy: <span class="subst">&#123;<span class="number">100</span> * correct / total:<span class="number">.2</span>f&#125;</span>%&#x27;</span>)</span><br></pre></td></tr></table></figure><h1 id="模型保存和加载"><a href="#模型保存和加载" class="headerlink" title="模型保存和加载"></a>模型保存和加载</h1><p><img data-src="/./../images/image-20251004151238326.png" alt="image-20251004151238326"></p><p><img data-src="/./../images/image-20251004151314736.png" alt="image-20251004151314736"></p><p>优点：保存了模型的完整结构</p><p>缺点：模型文件体积大</p><p><img data-src="/./../images/image-20251004151411703.png" alt="image-20251004151411703"></p><p><img data-src="/./../images/image-20251004151513660.png" alt="image-20251004151513660"></p><p><img data-src="/./../images/image-20251004151718462.png" alt="image-20251004151718462"></p><p><img data-src="/./../images/image-20251004151824370.png" alt="image-20251004151824370"></p><h1 id="计算机视觉模块"><a href="#计算机视觉模块" class="headerlink" title="计算机视觉模块"></a>计算机视觉模块</h1><p><img data-src="/./../images/image-20251004155143064.png" alt="image-20251004155143064"></p><p><a target="_blank" rel="noopener" href="https://docs.pytorch.ac.cn/vision/stable/index.html">torchvision — Torchvision 0.23 文档 - PyTorch 文档</a></p><p><img data-src="/./../images/image-20251004155245827.png" alt="image-20251004155245827"></p><p><img data-src="/./../images/image-20251004155334340.png" alt="image-20251004155334340"></p><p><img data-src="/./../images/image-20251004155405152.png" alt="image-20251004155405152"></p><p><img data-src="/./../images/image-20251004155502079.png" alt="image-20251004155502079"></p><p><img data-src="/./../images/image-20251004155518151.png" alt="image-20251004155518151"></p><p><a target="_blank" rel="noopener" href="https://docs.pytorch.ac.cn/vision/stable/transforms.html">转换图像、视频、边界框等 — Torchvision 0.23 文档 - PyTorch 文档</a></p><p><img data-src="/./../images/image-20251004155619357.png" alt="image-20251004155619357"></p><p><img data-src="/./../images/image-20251004155741508.png" alt="image-20251004155741508"></p><p><img data-src="/./../images/image-20251004155918237.png" alt="image-20251004155918237"></p><p><img data-src="/./../images/image-20251004160011322.png" alt="image-20251004160011322"></p><p><img data-src="/./../images/image-20251004160030493.png" alt="image-20251004160030493"></p><p><img data-src="/./../images/image-20251004160137783.png" alt="image-20251004160137783"></p><p><img data-src="/./../images/image-20251004160152624.png" alt="image-20251004160152624"></p><p><img data-src="/./../images/image-20251004160456282.png" alt="image-20251004160456282"></p><p><img data-src="/./../images/image-20251004160647088.png" alt="image-20251004160647088"></p><p><img data-src="/./../images/image-20251004160659944.png" alt="image-20251004160659944"></p><p><img data-src="/./../images/image-20251004160819065.png" alt="image-20251004160819065"></p><p><img data-src="/./../images/image-20251004160832338.png" alt="image-20251004160832338"></p><h1 id="模型部署"><a href="#模型部署" class="headerlink" title="模型部署"></a>模型部署</h1><p><img data-src="/./../images/image-20251004161036193.png" alt="image-20251004161036193"></p><p><img data-src="/./../images/image-20251004161115819.png" alt="image-20251004161115819"></p><p><img data-src="/./../images/image-20251004161131582.png" alt="image-20251004161131582"></p><p><img data-src="/./../images/image-20251004161250282.png" alt="image-20251004161250282"></p><p><img data-src="/./../images/image-20251004161406034.png" alt="image-20251004161406034"></p><p><img data-src="/./../images/image-20251004161425662.png" alt="image-20251004161425662"></p><p><img data-src="/./../images/image-20251004161556149.png" alt="image-20251004161556149"></p><p><img data-src="/./../images/image-20251004161609676.png" alt="image-20251004161609676"></p><p><img data-src="/./../images/image-20251004161850169.png" alt="image-20251004161850169"></p><h1 id="图像分类略讲"><a href="#图像分类略讲" class="headerlink" title="图像分类略讲"></a>图像分类略讲</h1><p><img data-src="/./../images/image-20251004161924416.png" alt="image-20251004161924416"></p><p><img data-src="/./../images/image-20251004162126318.png" alt="image-20251004162126318"></p></div><footer class="post-footer"><div class="post-copyright"><ul><li class="post-copyright-author"><strong>本文作者： </strong>MaJianyu</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://mjy.js.org/2025/10/04/Python0004/" title="Python学习笔记其四">https://mjy.js.org/2025/10/04/Python0004/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="post-tags"><a href="/tags/Python/" rel="tag"># Python</a></div><div class="post-nav"><div class="post-nav-item"><a href="/2025/10/03/Change-the-Windows-Chinese-user-home-folder-to-English/" rel="prev" title="将Windows中文用户主文件夹修改为英文"><i class="fa fa-angle-left"></i> 将Windows中文用户主文件夹修改为英文</a></div><div class="post-nav-item"><a href="/2025/10/14/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20%20TCSVT%202024%20%20MMI-Det%EF%BC%9A%E6%8E%A2%E7%B4%A2%E5%8F%AF%E8%A7%81%E5%85%89%E4%B8%8E%E7%BA%A2%E5%A4%96%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E3%80%91/" rel="next" title="【论文阅读 | TCSVT 2024 | MMI-Det：探索可见光与红外目标检测的多模态融合】">【论文阅读 | TCSVT 2024 | MMI-Det：探索可见光与红外目标检测的多模态融合】 <i class="fa fa-angle-right"></i></a></div></div></footer></article></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; 2021 – <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">MaJianyu</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span>站点总字数：</span> <span title="站点总字数">117k</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span>站点阅读时长 &asymp;</span> <span title="站点阅读时长">3:32</span></span></div><div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动</div><a href="https://icp.gov.moe/?keyword=20216556" target="_blank">萌ICP备20216556号</a></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div><div class="sidebar-dimmer"></div><div class="back-to-top" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up fa-lg"></i> <span>0%</span></div><a href="https://github.com/majianyu2007" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script src="https://mjy.js.org/js/darkmode@1.5.7.min.js"></script><script>var options = {
  bottom: '16px',
  right: '16px',
  left: 'unset',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();</script></body></html>
<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 8.0.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous" defer></script><script class="next-config" data-name="main" type="application/json">{"hostname":"mjy.js.org","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.25.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":"ture","style":"default"},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script><meta name="description" content="MMI-Det：探索可见光与红外目标检测的多模态融合"><meta property="og:type" content="article"><meta property="og:title" content="【论文阅读 | TCSVT 2024 | MMI-Det：探索可见光与红外目标检测的多模态融合】"><meta property="og:url" content="https://mjy.js.org/2025/10/14/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20%20TCSVT%202024%20%20MMI-Det%EF%BC%9A%E6%8E%A2%E7%B4%A2%E5%8F%AF%E8%A7%81%E5%85%89%E4%B8%8E%E7%BA%A2%E5%A4%96%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E3%80%91/index.html"><meta property="og:site_name" content="TranquilYu&#39;s Blog"><meta property="og:description" content="MMI-Det：探索可见光与红外目标检测的多模态融合"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://mjy.js.org/images/image-20251014174923042-1760435411753-1.png"><meta property="og:image" content="https://mjy.js.org/images/image-20251014201352915.png"><meta property="article:published_time" content="2025-10-14T00:00:00.000Z"><meta property="article:modified_time" content="2025-10-19T09:43:10.398Z"><meta property="article:author" content="MaJianyu"><meta property="article:tag" content="傅里叶变换"><meta property="article:tag" content="图像融合"><meta property="article:tag" content="多光谱目标检测"><meta property="article:tag" content="多模态融合"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://mjy.js.org/images/image-20251014174923042-1760435411753-1.png"><link rel="canonical" href="https://mjy.js.org/2025/10/14/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20%20TCSVT%202024%20%20MMI-Det%EF%BC%9A%E6%8E%A2%E7%B4%A2%E5%8F%AF%E8%A7%81%E5%85%89%E4%B8%8E%E7%BA%A2%E5%A4%96%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E3%80%91/"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://mjy.js.org/2025/10/14/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20%20TCSVT%202024%20%20MMI-Det%EF%BC%9A%E6%8E%A2%E7%B4%A2%E5%8F%AF%E8%A7%81%E5%85%89%E4%B8%8E%E7%BA%A2%E5%A4%96%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E3%80%91/","path":"2025/10/14/【论文阅读  TCSVT 2024  MMI-Det：探索可见光与红外目标检测的多模态融合】/","title":"【论文阅读 | TCSVT 2024 | MMI-Det：探索可见光与红外目标检测的多模态融合】"}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>【论文阅读 | TCSVT 2024 | MMI-Det：探索可见光与红外目标检测的多模态融合】 | TranquilYu's Blog</title><script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous" defer></script><script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script><script src="/js/pjax.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.5.0/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script><script src="/js/third-party/search/local-search.js" defer></script><script src="/js/third-party/pace.js" defer></script><script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script><script src="/js/third-party/math/mathjax.js" defer></script><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><link rel="alternate" href="/atom.xml" title="TranquilYu's Blog" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><p class="site-title">TranquilYu's Blog</p><i class="logo-line"></i></a></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E6%91%98%E8%A6%81"><span class="nav-number">1.</span> <span class="nav-text">1.摘要</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E5%BC%95%E8%A8%80"><span class="nav-number">2.</span> <span class="nav-text">2.引言</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%88%E5%89%8D%E6%96%B9%E6%B3%95"><span class="nav-number">2.1.</span> <span class="nav-text">先前方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E8%B4%A1%E7%8C%AE"><span class="nav-number">2.2.</span> <span class="nav-text">主要贡献</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E6%96%B9%E6%B3%95"><span class="nav-number">3.</span> <span class="nav-text">3.方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%88%E5%89%8D%E6%96%B9%E6%B3%95-1"><span class="nav-number">3.1.</span> <span class="nav-text">先前方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#A-%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88"><span class="nav-number">3.1.1.</span> <span class="nav-text">A. 图像融合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#B-%E5%A4%9A%E5%85%89%E8%B0%B1%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="nav-number">3.1.2.</span> <span class="nav-text">B. 多光谱目标检测</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#C-%E5%9F%BA%E4%BA%8E%E9%A2%91%E7%8E%87%E7%9A%84%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E6%96%B9%E6%B3%95"><span class="nav-number">3.1.3.</span> <span class="nav-text">C. 基于频率的特征提取方法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AC%E6%96%87%E6%89%80%E6%8F%90%E5%87%BA%E7%9A%84%E6%96%B9%E6%B3%95"><span class="nav-number">3.2.</span> <span class="nav-text">本文所提出的方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#A-%E6%80%BB%E4%BD%93%E7%BB%93%E6%9E%84"><span class="nav-number">3.2.1.</span> <span class="nav-text">A. 总体结构</span></a></li></ol></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">MaJianyu</p><div class="site-description" itemprop="description">永远相信，美好的事情即将发生。</div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">14</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">9</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">35</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/majianyu2007" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;majianyu2007" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/600064036" title="BiliBili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;600064036" rel="noopener me" target="_blank"><i class="fa-brands fa-bilibili fa-fw"></i>BiliBili</a></span></div><div class="cc-license animated" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a></div></div></div></div></aside></div><div class="main-inner post posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://mjy.js.org/2025/10/14/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20%20TCSVT%202024%20%20MMI-Det%EF%BC%9A%E6%8E%A2%E7%B4%A2%E5%8F%AF%E8%A7%81%E5%85%89%E4%B8%8E%E7%BA%A2%E5%A4%96%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E3%80%91/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.gif"><meta itemprop="name" content="MaJianyu"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="TranquilYu's Blog"><meta itemprop="description" content="永远相信，美好的事情即将发生。"></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="【论文阅读 | TCSVT 2024 | MMI-Det：探索可见光与红外目标检测的多模态融合】 | TranquilYu's Blog"><meta itemprop="description" content="MMI-Det：探索可见光与红外目标检测的多模态融合"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">【论文阅读 | TCSVT 2024 | MMI-Det：探索可见光与红外目标检测的多模态融合】</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2025-10-14 08:00:00" itemprop="dateCreated datePublished" datetime="2025-10-14T08:00:00+08:00">2025-10-14</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2025-10-19 17:43:10" itemprop="dateModified" datetime="2025-10-19T17:43:10+08:00">2025-10-19</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a> </span></span><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>5.5k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>10 分钟</span></span></div><div class="post-description">MMI-Det：探索可见光与红外目标检测的多模态融合</div></div></header><div class="post-body" itemprop="articleBody"><p>[TOC]</p><p><img data-src="/./../images/image-20251014174923042-1760435411753-1.png" alt="image-20251014174923042"></p><p>题目：MMI-Det: Exploring Multi-Modal Integration for<br>Visible and Infrared Object Detection</p><p>期刊：TCSVT(IEEE Transactions on Circuits and Systems for Video Technology)</p><p>论文链接：<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/10570450">Link</a></p><p>关键词：Multi-spectral object detection(多光谱目标检测), multi-modal integration(多模态融合), image fusion(图像融合), Fourier transformation(傅里叶变换).</p><p>代码：未开源</p><p>年份：2024</p><h2 id="1-摘要"><a href="#1-摘要" class="headerlink" title="1.摘要"></a>1.摘要</h2><p>可见光-红外(VIS-IR)目标检测是一项具有挑战性的目标检测任务，其通过融合<strong>可见光(RGB)图像数据</strong>和<strong>红外(IR)图像数据</strong>，以提供场景中目标的类别和位置信息。因此，该任务的核心在于融合可见光和红外模态中的<strong>互补</strong>信息，从而为检测提供更优的目标检测结果。现有方法主要面临对可见光-红外模态信息的感知与融合能力不足，以及难以平衡融合与检测任务优化方向的问题。为解决这些问题，我们提出了<strong>MMI-Det</strong>，一种用于可见光-红外目标检测的多模态融合方法。该方法能够实现可见光-红外模态中互补信息的良好融合，并输出准确且鲁棒的目标信息。具体而言，为提升模型在可见光-红外图像层面的环境感知能力，我们设计了<strong>轮廓增强模块(Contour Enhancement Module)</strong>。此外，为从可见光和红外模态中提取互补信息，我们设计了<strong>融合聚焦模块(Fusion Focus Module)</strong>，该模块能够提取可见光和红外模态的不同频率谱特征，并聚焦于不同空间位置的目标关键信息。同时，我们设计了<strong>对比度桥接模块(Contrast Bridge Module)</strong>，以提升在可见光-红外场景中提取模态不变特征的能力。最后，为确保模型能够平衡图像融合与目标检测的优化方向，我们设计了<strong>信息引导模块(Info Guided Module)</strong>，以提升模型训练优化的有效性。我们在公开的FLIR、M3FD、LLVIP、TNO和MSRS数据集上进行了大量实验，与现有方法相比，我们的方法凭借强大的多模态信息感知能力取得了更优的性能。</p><h2 id="2-引言"><a href="#2-引言" class="headerlink" title="2.引言"></a>2.引言</h2><h3 id="先前方法"><a href="#先前方法" class="headerlink" title="先前方法"></a>先前方法</h3><p>目标检测是计算机视觉领域的一个基本问题。为了确认和定位图像中某些特定类别的实例，目标检测已经被研究了许多年。然而，现有方法主要聚焦于可见光(RGB)下的目标检测，因此这便限制了目标检测的检测范围——难以在夜间准确识别目标。为了实现全天候、动态环境下的目标检测，满足多领域的需求，可见光-红外目标检测因具有更广泛的应用前景而被提出，并日益受到该领域研究者的关注。可见光-红外目标检测需要融合两种模态下目标的互补信息，以感知场景中目标的位置和类别。然而，由于两种模态之间存在较大的异质性差异，如何感知并提取模态间的关键信息成为一个具有挑战性的问题。</p><p>可见光和红外线这两种模态的图像之间存在显著差异。为了补充这些差异显著的可见光-红外图像的信息，目前一些可见光-红外(VIS-IR)目标检测方法采用两阶段方法设计模型，此方法可概括为“先融合，后检测”。这些方法通过设计多种图像融合策略生成包含更丰富信息的融合图像，并基于这些融合图像，利用单模态目标检测方法对融合图像中的目标进行检测。然而当前的实现方法将融合与检测划分为两个独立的优化任务，难以保持两个任务的优化方向一致。因此这些方法可能导致更差的检测结果。因此，如何使模型能够充分提取两种模态的互补信息，为后续检测任务提供更丰富的目标特征信息，已成为一个重要问题。</p><p>为了解决可见光-红外目标检测中的上述问题，我们尝试设计一种利用多级模态融合的新架构。在本文中，我们提出一种针对可见光和红外目标的多模态融合方法：<strong>MMI-Det</strong></p><h3 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h3><ul><li><p>我们提出了<strong>MMI-Det</strong>，一种用于VIS-IR目标检测的新框架。该框架提供了一种联合优化融合与检测任务的解决方案，从而实现了准确且鲁棒的多光谱目标检测结果。在公开数据集(FLIR、M3FD、LLVIP、TNO、MSRS)上进行的大量实验证明了我们的<strong>MMI-Det</strong> 的有效性，其性能优于先前的方法；</p></li><li><p>我们提出<strong>轮廓增强模块(Contour Enhancement Module)</strong>，该模块有助于方法感知复杂动态场景中物体的轮廓，并提升目标检测性能；</p></li><li><p>我们设计了<strong>融合聚焦模块(Fusion Focus Module)</strong>，以使得该方法能够在不同空间区域下感知并融合可见光-红外模态的目标细节信息；</p></li><li><p>**对比度桥接模块(Contrast Bridge Module)**旨在利用对比学习的思想，将可见光-红外数据分离为正负样本对。其能够引导模型提升在可见光-红外场景中感知模态不变特征的能力；</p></li><li><p>**信息引导模块(Info Guided Module)**旨在引导我们的模型在训练过程中更有效地融合两种模态的特征信息。</p></li></ul><h2 id="3-方法"><a href="#3-方法" class="headerlink" title="3.方法"></a>3.方法</h2><h3 id="先前方法-1"><a href="#先前方法-1" class="headerlink" title="先前方法"></a>先前方法</h3><h4 id="A-图像融合"><a href="#A-图像融合" class="headerlink" title="A. 图像融合"></a>A. 图像融合</h4><p>目前已经有许多较为成熟的图像融合方法：</p><ul><li><strong>CCAFusion</strong>由Li 等人提出，设计了一种基于坐标注意力的跨模态图像融合策略，该策略由特征感知融合模块和特征增强融合模块组成；</li><li><strong>UNFusion</strong>由Wang 等人提出，他们引入了一个统一的多尺度密集连接融合网络，使用一个多尺度编码-解码架构来提取和重建多尺度深度特征；</li><li><strong>Laplacian pyramid fusion network</strong>由Yao 等人提出利用层级指导来使用像素级的可见性保留的Laplacian 阳光来生成层级可见性地图；</li><li><strong>DATFuse</strong>由Tang 等人提出，它引入了一个用于重要特征提取的双注意力残余模块来实现图像融合；</li><li><strong>unsupervised image fusion network</strong>由Xu 等人提出，该网络可通过特征提取和信息测量源图像的重要性；</li><li><strong>deep network cascade feature learning module</strong>由Liu 等人提出。他们的方法采用了一种从粗到细的深度架构来从多模态图像中学习多尺度特征；</li><li>Tang 等人受生物视觉系统的启发，深入研究了早期视觉信息处理的建模机制建模。他们的可见光-红外图像融合方法利用了两种模式的优势。他们随后提出了一种光感知渐进式图像融合网络，称为 PIAF融合网络。</li></ul><p>然而，尽管上述方法探索了可见光红外图像融合的各种潜力，但这些方法将融合和检测分为两个独立的优化任务，很难保持两个任务的优化方向一致。<br>这意味着图像融合的最佳区域通常不是物体检测的最佳区域，从而导致图像融合效果不理想。</p><h4 id="B-多光谱目标检测"><a href="#B-多光谱目标检测" class="headerlink" title="B. 多光谱目标检测"></a>B. 多光谱目标检测</h4><p>多光谱目标检测方法采用<strong>两阶段训练</strong>方式，将<strong>融合</strong>与<strong>检测</strong>看作两个独立的任务分别进行优化，这可能导致两者之间的优化目标不一致。研究人员，意识到这一局限性，因此开发了新的多光谱目标检测方法，将图像融合与检测整合到一个统一的框架中。</p><ul><li><p>Wagner等人提出了一种<strong>融合-精化(fuse-and-refine)方法</strong>，该方法采用循环图像融合方式，通过迭代精化每个光谱特征以提升检测性能；</p></li><li><p>Fang等人则采用了不同的方法，将<strong>Transformer</strong>与<strong>YOLO检测框架</strong>相结合，设计了一种适用于可见光-红外(VIS-IR)检测任务的多光谱检测方法；</p></li><li><p>Yun等人提出了<strong>跨模态与模态内加权交叉融合网络(Infusion-Net)</strong>，该网络通过利用可见光-红外图像对的优势来增强目标检测性能；</p></li><li><p>Zhou等人提出了一种<strong>可见光-红外特征融合网络</strong>，该网络通过双边逆融合提取目标边界，并通过多级融合捕获互补信息。</p></li></ul><p>然而，尽管这些方法将融合与检测任务整合到单一建模框架中，但它们在探索面向检测的可见光-红外模态特征融合方面仍存在不足，且在自主且全面地融合多光谱信息方面尚未得到充分研究。因此，如何使模型充分提取两种模态的互补信息，为后续检测任务提供更丰富的目标特征信息，成为一个重要问题。</p><h4 id="C-基于频率的特征提取方法"><a href="#C-基于频率的特征提取方法" class="headerlink" title="C. 基于频率的特征提取方法"></a>C. 基于频率的特征提取方法</h4><p>频域分析作为图像信号处理领域的基石，在图像分类、纹理提取、图像融合以及超分辨率等众多领域发挥了重要作用。</p><ul><li><p>为解决人脸活体检测问题，Stuchi等人提出了一种基于<strong>傅里叶分析</strong>的特征提取方法。</p></li><li><p>Xiao等人设计的<strong>FAFusion</strong>通过提取可见光-红外图像对中的高频信息来感知物体边缘和纹理细节，从而增强融合图像的细节。</p></li><li><p>此外，针对图像超分辨率问题，Li等人设计了一种基于频域变换的网络，该网络利用卷积定理将空间域的卷积运算转化为频域的乘积运算。</p></li><li><p>Fang等人提出了一种基于高频Transformer的网络，用于磁共振图像的超分辨率重建。</p></li></ul><p>尽管上述方法已从不同角度研究了多种基于频率的特征提取方法，但如何在可见光-红外场景中利用频域分析以提升模型在复杂场景中感知物体位置和轮廓的能力仍有待进一步探索和研究。</p><h3 id="本文所提出的方法"><a href="#本文所提出的方法" class="headerlink" title="本文所提出的方法"></a>本文所提出的方法</h3><h4 id="A-总体结构"><a href="#A-总体结构" class="headerlink" title="A. 总体结构"></a>A. 总体结构</h4><ul><li>基于双流YOLOv5框架</li></ul><p>对于输入图像，我们令V和I分别表示可见光图像和红外图像。则可见光图像的输入可表示为<br>$$<br>X_V &#x3D; {x_V | x_V \in \mathbb{R}^{C \times H \times W}}<br>$$<br>红外图像的输入可表示为<br>$$<br>X_I &#x3D; {x_I | x_I \in \mathbb{R}^{C \times H \times W}}<br>$$<br>其中C、H和W分别对应图像的通道、高度和宽度。</p><p>在一个批次的训练过程中，共有B幅图像，其中$x_i^V$和$x_i^I$的数量相同，$i \in {1, 2, \ldots, B&#x2F;2}$。输入的可见光-红外图像将首先通过轮廓增强模块(Contour Enhancement Module)，如下式所示：<br>$$<br>\begin{split}<br>F_{\text{V}}^{CEM} &amp;&#x3D; CEM(X_{\text{V}}), \<br>F_{\text{I}}^{CEM} &amp;&#x3D; CEM(X_{\text{I}}).<br>\end{split}<br>$$<br>在此，$F_{\text{V}}^{CEM}$和$F_{\text{I}}^{CEM}$表示经过CEM处理后的可见光-红外特征。接下来，为了使特征在不丢失过多信息的前提下能够在计算上进行降维，我们引入了FOC，该方法使用切片操作，将高分辨率特征图分割为多个低分辨率特征图。FOC的这种策略性分割以紧凑形式保留了关键空间信息，在促进更快处理的同时，保持了准确目标检测所需的特征完整性。这些FOC模块的输出特征被输入至Conv和C3模块。C3采用多尺度特征融合方法和跨通道信息传递机制来提升特征表示能力。通过将FOC与C3有效结合，网络同时受益于降维和特征丰富性，从而提升了检测性能。需要注意的是，FOC和C3均已在YOLOv5中可用。该过程如下所示：</p><p>$$<br>\begin{split}<br>F_{\text{V}}^{C3} &amp;&#x3D; C3(\text{Conv}(\text{FOC}(F_{\text{V}}^{CEM}))), \<br>F_{\text{I}}^{C3} &amp;&#x3D; C3(\text{Conv}(\text{FOC}(F_{\text{I}}^{CEM}))).<br>\end{split}<br>$$</p><p>公式2中的Conv模块和C3模块能够提升模型的特征提取能力。为了引导模型进行有效的训练优化，我们借鉴对比学习的思想设计了对比桥接模块(Contrastive Bridge Module, CBM)，并设计了损失函数$\mathcal{L}_{CB}$ :</p><p>$$<br>\mathcal{L}<em>{CB} &#x3D; CBM(F</em>{\text{V}}^{C3}, F_{\text{I}}^{C3}).<br>$$</p><p>在此， $\mathcal{L}<em>{CB}$ 可用作损失函数以引导模型学习模态不变信息。经过上述模块后，可见光特征$F</em>{\text{V}}^{C3}$与红外特征 $F_{\text{I}}^{C3}$ 被输入至融合聚焦模块(Fusion Focus Module, FFM)。MMI-Det设计了多个FFM用于不同深度的特征融合。具体而言，FFM的结构如下式所示：</p><p>$$<br>F_{\text{V}}^{FFM}, F_{\text{I}}^{FFM} &#x3D; FFM(F_{\text{V}}^{C3}, F_{\text{I}}^{C3}).<br>$$</p><p>FFM 充分融合两种模态特征，并将融合后的特征反馈至两个分支。它们与在各自的分支上的特征相加，并一同被发送至下一个特征提取-融合阶段：</p><p>$$<br>\begin{align*}<br>F_{\text{V}}^{add} &amp;&#x3D; F_{\text{V}}^{FFM} + F_{\text{V}}^{C3}, \<br>F_{\text{I}}^{add} &amp;&#x3D; F_{\text{I}}^{FFM} + F_{\text{I}}^{C3}, \<br>F_{\text{V-I}}^{add_1} &amp;&#x3D; F_{\text{V}}^{add} + F_{\text{I}}^{add}.<br>\end{align*}<br>$$</p><p>在上式中，相加特征 $F_{\text{V}}^{add}$ 和 $F_{\text{I}}^{add}$ 被传送到后续阶段，我们设计了共 $i$ 组此类阶段，以从不同深度充分提取两种模态中的目标信息。当前阶段的融合特征将被保存为 $F_{\text{V-I}}^{add_1}$ 。最终结果通过检测头(Detect Head)输出，如下图所示。相关公式如下：</p><p><img data-src="/./../images/image-20251014201352915.png" alt="image-20251014201352915"></p><p>$$<br>Pred &#x3D; DetectHead(F_{\text{V-I}}^{add_1}, F_{\text{V-I}}^{add_2}, \ldots, F_{\text{V-I}}^{add_i}).<br>$$</p></div><footer class="post-footer"><div class="post-copyright"><ul><li class="post-copyright-author"><strong>本文作者： </strong>MaJianyu</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://mjy.js.org/2025/10/14/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20%20TCSVT%202024%20%20MMI-Det%EF%BC%9A%E6%8E%A2%E7%B4%A2%E5%8F%AF%E8%A7%81%E5%85%89%E4%B8%8E%E7%BA%A2%E5%A4%96%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E3%80%91/" title="【论文阅读 | TCSVT 2024 | MMI-Det：探索可见光与红外目标检测的多模态融合】">https://mjy.js.org/2025/10/14/【论文阅读 TCSVT 2024 MMI-Det：探索可见光与红外目标检测的多模态融合】/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="post-tags"><a href="/tags/%E5%A4%9A%E5%85%89%E8%B0%B1%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag"># 多光谱目标检测</a> <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88/" rel="tag"># 多模态融合</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E8%9E%8D%E5%90%88/" rel="tag"># 图像融合</a> <a href="/tags/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/" rel="tag"># 傅里叶变换</a></div><div class="post-nav"><div class="post-nav-item"><a href="/2025/10/04/Python0004/" rel="prev" title="Python学习笔记其四"><i class="fa fa-angle-left"></i> Python学习笔记其四</a></div><div class="post-nav-item"><a href="/2025/10/18/MATLAB0001/" rel="next" title="MATLAB基础作业其一">MATLAB基础作业其一 <i class="fa fa-angle-right"></i></a></div></div></footer></article></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; 2021 – <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">MaJianyu</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span>站点总字数：</span> <span title="站点总字数">49k</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span>站点阅读时长 &asymp;</span> <span title="站点阅读时长">1:30</span></span></div><div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动</div><a href="https://icp.gov.moe/?keyword=20216556" target="_blank">萌ICP备20216556号</a></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div><div class="sidebar-dimmer"></div><div class="back-to-top" role="button" aria-label="返回顶部"><i class="fa fa-arrow-up fa-lg"></i> <span>0%</span></div><a href="https://github.com/majianyu2007" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script src="js/darkmode@1.5.7.min.js"></script><script>var options={bottom:"16px",right:"16px",left:"unset",time:"0.5s",mixColor:"transparent",backgroundColor:"transparent",buttonColorDark:"#100f2c",buttonColorLight:"#fff",saveInCookies:!0,label:"🌓",autoMatchOsTheme:!0};const darkmode=new Darkmode(options);window.darkmode=darkmode,darkmode.showWidget()</script></body></html>